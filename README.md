# Zoonosis

Machine learning and deep learning models to predict -- 
- Will a given virus sequence infect humans?
- What is the host of a given virus sequence?
- What are the zoonotic mutations in an animal viral sequence?

## Repository Organization
- **deployment**
  - arc: shell scripts for deployments in arc
- **input**: 
    - config-files: yaml config files for data-preprocessing, prediction, and evaluation tasks.
    - data: raw fasta files of protein sequences and five independent splits with training and testing files
      - HEV virus protein sequences downloaded from
      - all mammlian and aves virus protein sequences download from UniRef90.
  raw: Folder containing raw protein sequences in fasta format. 
    - processed: Folder containing all preprocessed protein sequences with labels to be supplied as input to classification models.
- deployment:Scripts needed to execute the pipeline in remote servers like csbgpu and arc. 
    - arc: Scripts needed to execute the pipeline in arc.
- input: all inputs
    - config-files: Config files needed as input to run the pipleine
        - data-processing: Config files for data processing pipeline
        - prediction: Config files for prediction pipeline 
        - evaluation: Config files for evaluation pipeline

- output: 
    - raw: Output files with predictions from the classification models.
    - evaluation: Intermediary output files with evaluation metric values generated by evaluation pipeline.
    - visualization: Result figures/visualizations.
    - trained-models: Trained deep learning models with checkpoints (if applicable).
- src: source code


# About
Inspired by the UMAP projection clustering as pointed out in [Learning the language of viral evolution and escape](https://www.science.org/doi/10.1126/science.abd7331), language models seem to be able to cluster data very well during pretraining without supervision. We make a simple pipeline with yaml files that trains models and evaluates the predictive performance with and without pretraining.

# Prerequisites:
To run on ARC, you must copy this directory to ~/ on ARC and run deployment/setup1.sh and deployment/setup2.sh, which will set up a conda env labeled BioNLP.

### Data
Data is stored under ./data/hep in the form of Fasta files delimited by |, which contains protien, host, genotype in this order.
Data can be generated in GenbankData/ given you have an accession list.

### Dependencies
Install python dependencies via 
``` 
pip install -R ./requirements.txt
```

### Usage
General usage to call a yaml config and output to a log file.
```
python src/pipeline.py -c config/hepConfig.yaml > $RESULTS_DIR/hep_host_transfer.$(date +%Y_%b_%d_%H_%M).log 2>&1
```

### ARC Setup
- Instantiate conda environment
```
bash
conda create -n zoonosis
pip install numpy --pre torch --index-url https://download.pytorch.org/whl/cu117
pip install -r requirements.txt
```



