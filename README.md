# VirProBERT: Language Model for Virus Host Prediction

![VirProBERT](figures/virus_host_prediction.png)

## Repository Organization
- **deployment**
  - arc: shell scripts for deployments in arc
  - pandemic-da: shell scripts for deployments in pandemic-da
- **input**: 
    - config-files: yaml config files for data-preprocessing, prediction, and evaluation tasks.
    - data: raw fasta files of protein sequences and five independent splits with training and testing files
      - HEV virus protein sequences downloaded from
      - all mammalian and aves virus protein sequences download from UniRef90.
  raw: Folder containing raw protein sequences in fasta format. 
    - processed: Folder containing all preprocessed protein sequences with labels to be supplied as input to classification models.
- **output**: 
    - raw: Output files with predictions from the classification models.
    - evaluation: Intermediary output files with evaluation metric values generated by evaluation pipeline.
    - visualization: Result figures/visualizations.
    - logs: Log files generated during experiment executions.
- **src**: source code
---
## Code and dependencies
- Clone the GitHub repository at the desired location.
- Setup conda environment 
    ```shell
    bash
    conda create -n virprobert python=3.11.8
    conda activate virprobert
    pip install -r requirements.txt
    ```
- [Install pytorch](https://pytorch.org/get-started/locally/) based on the GPU/CPU configuration.

### Create required folders
- Create input and output folders
```shell
cd zoonosis
mkdir -p zoonosis/input/data
mkdir zoonosis/output
```

### Setup Weights & Biases
1. Create an account in [Weights & Biases](https://wandb.ai/site/).
2. Create a new project in Weights and Biases named `zoonosis-host-prediction`.
3. Setup the `wandb` library by completing [Step 1 in the Quickstart](https://wandb.ai/quickstart?utm_source=app-resource-center&utm_medium=app&utm_term=quickstart).
    - Note: Do not forget to log in to Weights and Biases (`wandb login`) in the server where you intend to execute the experiment.
---
## Usage
```shell
python src/run.py -c <path-to-config-file>
```
Example
```shell
python src/run.py -c input/config-files/virus_host_prediction/uniref90/fine-tuning-virprobert.yaml
```
---
## Pipelines
The pipelines implemented and their corresponding configuration types (`config_type` parameter in the config files) are as follows -

| Pipeline                                                         | Config Type                                     | Supported Models/ Examples                          | Example config                                                                                                                                                                                         |
|:-----------------------------------------------------------------|:------------------------------------------------|:----------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Masked Language Modeling                                         | masked_language_modeling                        | VirProBERT Segment Encoder                          | [uniref90-mlm-msl256.yaml](input/config-files/transfer_learning/masked_language_modeling/uniref90-mlm-msl256.yaml)                                                                                     |
| Virus Host Prediction - train & test - VirProBERT                | virus_host_prediction                           | VirProBERT, VirProBERT ablations                    | [uniref90-fine-tuning-host-prediction-multi.yaml](input/config-files/virus_host_prediction/uniref90/fine-tuning-virprobert.yaml)                                                                       |
| Virus Host Prediction - train & test - external pLMs             | virus_host_prediction_external                  | ProtT5, ProstT5, ESM2, ESM3                         | [uniref90-fine-tuning-host-prediction-external-multi.yaml](input/config-files/virus_host_prediction/uniref90/fine-tuning-external-multi.yaml)                                                          |
| Virus Host Prediction - train & test - baseline models           | virus_host_prediction_baseline_deep_learning    | FNN, CNN, RNN, LSTM, Transformer-Encoder            | [host-prediction-all-models.yaml](input/config-files/virus_host_prediction/uniref90/baseline-deep-learning-models.yaml)                                                                                |
| Virus Host Prediction - train & test - kmer feature-based models | virus_host_prediction_baseline_machine_learning | LR, RF, SVM                                         | [engg-features-kmer-baseline.yaml](input/config-files/virus_host_prediction/uniref90/baseline-machine-learning-models-kmer.yaml)                                                                       |
| Virus Host Prediction - test only - VirProBERT                   | virus_host_prediction_test                      | VirProBERT for SARS-CoV-2 variants                  | [cov-s-host-prediction-multi-uniref90-sarscov2-variants.yaml](input/config-files/interpretability/sarscov2_variants/cov-s-host-prediction-multi-uniref90-sarscov2-variants.yaml)                       |
| Virus Host Prediction - test only - external pLMs                | virus_host_prediction_test_external             | ProtT5, ProstT5, ESM2, ESM3 for SARS-CoV-2 variants | [cov-s-host-prediction-multi-uniref90-sarscov2-variants-external.yaml](input/config-files/interpretability/sarscov2_variants/cov-s-host-prediction-multi-uniref90-sarscov2-variants-external.yaml)     |
| Evaluation of outputs                                            | evaluation                                      | AUPRC, AUROC, Precision, Recall, Accuracy, F1       | [uniref90-embl-host-prediction-multi-evaluation-all-models.yaml](input/config-files/evaluation/uniref90/uniref90-embl-host-prediction-multi-evaluation-all-models.yaml)                                |
| Few Shot Learning - unseen and rare hosts                        | few_shot_learning                               | VirProBERT                                          | [uniref90-fine-tuning-host-prediction-non-idv-multi-few-shot-learning.yaml](input/config-files/few_shot_learning/novel_host/uniref90-fine-tuning-host-prediction-non-idv-multi-few-shot-learning.yaml) |
| Few Shot Learning - unseen viruses                               | few_shot_learning                               | VirProBERT                                          | [uniref90-fine-tuning-host-prediction-idv-multi-few-shot-learning.yaml](input/config-files/few_shot_learning/novel_virus/uniref90-fine-tuning-host-prediction-idv-multi-few-shot-learning.yaml)        |
| Perturbation Analysis - VirProBERT                               | perturbation                                    | VirProBERT                                          | [cov-s-host-prediction-multi-perturbed_dataset.yaml](input/config-files/interpretability/perturbation/uniref90/cov-s-host-prediction-multi-perturbed_dataset.yaml)                                     |
| Perturbation Analysis - external pLMs                            | perturbation_external                           | ProtT5, ProstT5, ESM2, ESM3                         | [cov-s-host-prediction-multi-perturbed_dataset-external.yaml](input/config-files/interpretability/perturbation/uniref90/cov-s-host-prediction-multi-perturbed_dataset-external.yaml)                   |
| Embedding generation - VirProBERT                                | embedding_generation                            | VirProBERT                                          | [uniref90-fine-tuning-host-prediction-multi-embedding.yaml](input/config-files/interpretability/embedding/uniref90-fine-tuning-host-prediction-multi-embedding.yaml)                                   |

## Scripts
The supported scripts and their respective python files

| Task                               | Script file                                                                                      |
|:-----------------------------------|:-------------------------------------------------------------------------------------------------|
| Dataset preprocessor               | [data_preprocessor.py](src/utils/scripts/data_preprocessor.py)                                   |
| Datasplit generator                | [data_split_generator.py](src/utils/scripts/data_split_generator.py)                             |
| Perturbation dataset generator     | [perturbation_dataset_generator.py](src/utils/scripts/perturbation_dataset_generator.py)         |
| Perturbation output post processor | [perturbation_output_post_processor.py](src/utils/scripts/perturbation_output_post_processor.py) |

---
## Config File Parameters
### Common parameters used in all configuration types

### Masked Language Modeling (`masked_language_modeling`)
### Fine-tuning VirProBERT for Virus Host Prediction (`virus_host_prediction`)
1. Configure a suitable experiment name to be used to reference the execution using the `experiment` parameter in the config.
2. Set the relative path to the input file(s) within `input_settings` using `input_dir` and `file_names` parameters.
3. Set the following sequence related parameters in `sequence_settings` with respect to the input data file -
   1. `id_col`: identifier column name
   2. `sequence_col`: Sequence column name
   3. `truncate`: Boolean (default: False) - should the sequence be truncated with respect to the configured maximum sequence length?
   4. `split_sequence`: Boolean (default: False) - should the sequence be *explicitly* segmented with respect to the configured maximum sequence length?
4. Set the path to the transformer-encoder pre-trained using masked language modeling and all related parameters in `pre_train_settings`
    1. Configure the transformer-encoder related parameters in `pre_train_settings.encoder_settings`
5. Configure the parameters related to fine-tuning the pre-trained model in `fine_tune_settings`
6. Configure the common names of the virus hosts species and other label related settings in `fine_tune_settings.label_settings`
7. The different types fine-tuning models can be configured in `task_settings` and each model can be activated using its `active` flag.
    1. `data_parallel`: Enable parallel execution on multiple GPUs if available.
8. Configure the output directory and the prefix to be used while naming the output file in `output_settings`
9. Execute the fine-tuning experiment using
    ```shell
        python src/run.py --config <path-to-the-config-file>
    ```
---
## Adding an external pre-trained protein language model (pLM) to the Virus Host Prediction Pipeline
Currently the following external pLms are added to the pipeline: ProtT5, ProstT5, ESM2, ESM3
1. Create a child class of [ProteinSequenceClassification](src/models/protein_sequence_classification.py) within [models/external](src/models/external)
2. Implement the `get_embedding()` method that will generate the embeddings for a given batch of protein sequences.
3. Implement the `forward()` method ONLY if needed.The default implementation of `forward()` in [ProteinSequenceClassification](src/models/protein_sequence_classification.py) will do the following - 
   - call the `get_embedding()` method.
   - fine_tune for host prediction using a multi-layer perceptron neural network.
4. Create a Dataset class in [protein_sequence_custom_dataset.py](src/datasets/protein_sequence_custom_dataset.py) that will pre-process the protein sequences as per the requirement of the external model.
5. Add entries in the `model_map` and `dataset_map` in [mapper.py](src/utils/mapper.py) mapping the implementations of the model and dataset classes respectively.
6. Add entry for the model in `task_settings` in [uniref90-fine-tuning-host-prediction-external-multi.yaml](input/config-files/virus_host_prediction/uniref90/fine-tuning-external-multi.yaml).
    Note: the value of `name` parameter should match the key used in the mapping in the previous step.
7. Execute the fine-tuning experiment using
    ```shell
        python src/run.py --config input/config-files/transfer_learning/fine_tuning/uniref90-fine-tuning-host-prediction-external-multi.yaml
    ``` 

Example implementation of an external pLM: ProstT5 ([ProstT5_VirusHostPrediction](src/models/external/prost5_host_prediction.py), [ProteinSequenceProstT5Dataset](src/datasets/protein_sequence_custom_dataset.py))

---

## Dataset Preprocessing Pipeline
The [data_preprocessor.py](src/utils/scripts/data_preprocessor.py) allows you to process a dataset of viral protein sequences from UniProt or UniRef.


### Installing taxonKit and pytaxonkit
1. [Install taxonkit](https://bioinf.shenwei.me/taxonkit/download/#installation) using either Method 1 (preferred for Linux) or Method 2 (preferred for macOS)
2. [Download the taxonkit dataset](https://bioinf.shenwei.me/taxonkit/download/#dataset) and place it in the appropriate location. The absolute path to this directory must be provided using the `taxon_dir` argument where ever required in the below steps. 
3. [Install pytaxonkit](https://github.com/bioforensics/pytaxonkit).

> [!NOTE]
> The installation most likely will run into issues if you are using Windows OS. In such cases, switch to ARC.

### Functions available in [data_preprocessor.py](src/utils/scripts/data_preprocessor.py)
1. Convert a uniprot or uniref fasta file into a csv file.
```shell
python .\src\utils\scripts\data_preprocessor.py --fasta_to_csv --input_file <absolute-path-to-fasta-file> --output_dir <absolute-path-to-the folder-where-the-output-file-will-be-written> --input_type <uniprot, uniref50, uniref90, or uniref100> --id_col <name-of-the-id-column-for-the-output-file-example: uniprot_id, uniref90_id, uniref50_id> 
```
2. Get metadata for each viral sequence from UniProt. The metadata includes host for the sequence as recorded in UniProt, and the EMBL id for the sequence. We use the EMBL id to query EMBL in the next step to get the virus host corresponding to each viral protein sequence.
```shell
python .\src\utils\scripts\data_preprocessor.py --uniprot_metadata --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written> --input_type <uniprot, uniref50, uniref90, or uniref100 --id_col <name-of-the-id-column-defined-in-the-firs-step: uniprot_id, uniref90_id, uniref50_id> 
```
3. Query EMBL to get the virus hosts for each viral protein sequence using the EMBL id we fetched from UniProt in Step 2.
```shell
python .\src\utils\scripts\data_preprocessor.py --host_map_embl --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written> --id_col <name-of-the-id-column-defined-in-the-firs-step: uniprot_id, uniref90_id, uniref50_id>
```
4. Remove viral protein sequences without a host from EMBL.
```shell
python .\src\utils\scripts\data_preprocessor.py --prune_dataset --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written>
```
5. Get taxonomy information for the virus and virus hosts using taxonkit. 

> [!NOTE]
> This step requires that taxonkit and pytaxonkit are installed. Refer [Installing taxonKit and pytaxonkit](#installing-taxonkit-and-pytaxonkit) for installation instructions.

```shell
python src/utils/scripts/data_preprocessor.py --taxon_metadata --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written> --id_col <name-of-the-id-column-defined-in-the-firs-step: uniprot_id, uniref90_id, uniref50_id> --taxon_dir <absolute-path-to-the-taxon-directory-containing-taxonkit-files>
```
6. Filter for viruses at the species level
```shell
python src/utils/scripts/data_preprocessor.py --filter_species_virus --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written>
```
7. Filter for virus hosts at the species level
```shell
python src/utils/scripts/data_preprocessor.py --filter_species_virus_host -input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written>
```
8. Filter for virus hosts belonging to the _Vertebrata_ clade (virus hosts that are vertebrates)
> [!NOTE]
> This step requires that taxonkit and pytaxonkit are installed. Refer [Installing taxonKit and pytaxonkit](#installing-taxonkit-and-pytaxonkit) for installation instructions.

```shell
python src/utils/scripts/data_preprocessor.py --filter_vertebrates --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written> --taxon_dir <absolute-path-to-the-taxon-directory-containing-taxonkit-files>
```
9. Merge the sequence data to create the final dataset file.
> [!NOTE]
> The output files in steps 2 to 8 do not contain the sequences, but only the sequence id (example 'uniport_id') and any metadata from uniprot or NCBI taxonomy.
> This was done intentionally to save memory and avoid creating multiple files with the entire sequence. 
> That is why we need the final step 9 to bring all the amino acid sequences back and create the final dataset file. You can use the `--merge_sequence_data` step at any point if you need one of the intermediate files along with the sequence data.
```shell
python src/utils/scripts/data_preprocessor.py --merge_sequence_data <absolute-path-to-the-output-file-from-step-1-that-contains-the-amino-acid-sequences> --input_file <absolute-path-to-the-input-file-(output-file-from-the-previous-step)> --output_dir <absolute-path-to-the-folder-where-the-output-file-will-be-written> --id_col <name-of-the-id-column-defined-in-the-firs-step: uniprot_id, uniref90_id, uniref50_id>
```

The output file from Step 9 would yield a dataset of all viral protein sequences with virus hosts extracted from EMBL, viruses and virus hosts at the species level, and virus hosts that are vertebrates.
If you intend to do further filtering such as - 
1. virus hosts with atleast one percent prevalence in the dataset AND/ OR
2. protein sequences with sequence length within the 99.9 percentile AND/OR
3. analyse the dataset for the composition of viruses and virus hosts
OR any similar or additional custom filtering, please create a jupyter notebook and write custom code as needed.

This [jupyter notebook](src/jupyter_notebooks/datasets/generation/uniref90_embl_mapping_dataset_20240131_20240227.ipynb) contains code to do such custom filtering and analyses. Create your own notebook using this as a reference.