config_type: "host_prediction" # options: data_preprocessor, host_prediction, evaluation, transfer_learning

# Input Settings:
  ## initialize base input folder name
  ## provide path to dataset folder
input_settings:
  # Base input directory
  input_dir: "input/data/uniref90/20240131"

  # Name of file(s) in subdirectory to be read and processed.
  # Example: file_names: ["file_1.csv", "file_2.csv", "file_3.csv"]
  file_names: [ "uniref90_viridae_embl_hosts_pruned_metadata_species_vertebrates_w_seq_non_idv_t0.01_c5_seq_len_in_99.9percentile.csv" ]
  # seeds to split the files into training and testing
  # if provided, the number of seeds must match the number of iterations configured in classification_settings (n_iterations)
  split_seeds: [ 12612648, 31062180, 48918293, 55631155, 79221635 ]


classification_settings:
  experiment: "host_prediction"
  model_type: "nlp"
  n_iterations: 5
  split_input: True
  train_proportion: 0.8
  type: "multi"
  save_model: True

  sequence_settings:
    batch_size: 16
    id_col: "uniref90_id"
    sequence_col: "seq"
    max_sequence_length:
    truncate: False
    split_sequence: False
    feature_type: "token"  # supported values 'kmer', 'cgr', 'token'

  label_settings:
    label_col: "virus_host_name"
    exclude_labels: [ "nan" ]
    label_groupings:
      "Human": [ "Homo sapiens" ]
      "Pig": [ "Sus scrofa" ]
      "Capybara": [ "Hydrochoerus hydrochaeris" ]
      "Himalayan marmot": [ "Marmota himalayana" ]
      "Red junglefowl": [ "Gallus gallus" ]

  training_settings:
    n_epochs: 50
    max_lr: 1e-4
    pct_start: 0.10
    div_factor: 25.0
    final_div_factor: 10000.0

  models:
    - name: "fnn-l_10-d_1024-lr1e-3"
      active: False
      mode: "train" # supported values: train, test
      loss: "FocalLoss"
      depth: 10
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024
      manual_seed:  # whole number

    - name: "cnn-l_4-d_1024-k3s1-lr1e-3"
      active: False
      mode: "train" # supported values: train, test
      loss: "FocalLoss"
      depth: 4
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024
      kernel_size: 3
      stride: 1
      manual_seed:  # whole numbers

    - name: "rnn-l_6-d_1024-lr1e-5"
      active: False
      mode: "train" # supported values: train, test
      loss: "FocalLoss"
      depth: 6 # number of rnn layers
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024
      manual_seed:  # whole numbers

    - name: "lstm-l_2-d_1024-lr1e-3"
      active: False
      mode: "train" # supported values: train, test
      loss: "FocalLoss"
      depth: 2
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024
      manual_seed:  # whole numbers

    - name: "transformer-l_6-h_8-d_1024-msl2048-lr1e-4"
      active: True
      mode: "train" # supported values: train, test
      loss: "FocalLoss"
      with_convolution: False
      max_seq_len: 3036 # this is needed only for the positional encoding initialization
      n_heads: 8
      depth: 6
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024
      manual_seed:  # whole numbers

output_settings:
  output_dir: "output"
  results_dir: "raw"
  sub_dir: "uniref90_embl_vertebrates_non_idv_t0.01_c5_seq_len_in_99.9percentile/20240717/host_multi"
  prefix: "nlp_no_msl" # default: none; default file name = kmer_k<k>_lr_c<c>_<label>_<type>_tr<train_proportion>_n<n_iterations>_<output_prefix>_output.csv
