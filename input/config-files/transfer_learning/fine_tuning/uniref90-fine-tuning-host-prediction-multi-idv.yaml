config_type: "transfer_learning" # options: data_preprocessor, host_prediction, evaluation
config_sub_type: "host_prediction"

# Input Settings:
  ## initialize base input folder name
  ## provide path to dataset folder
input_settings:
  # Base input directory
  input_dir: "input/data/uniref90/20240131"

  # Name of file(s) in subdirectory to be read and processed.
  # Example: file_names: ["file_1.csv", "file_2.csv", "file_3.csv"]
  # file_names: [ "uniref90_final_msl1114.csv" ]
  file_names: [ "uniref90_viridae_embl_hosts_pruned_metadata_species_vertebrates_w_seq_idv.csv" ]
  pre_training_file_name: [ "uniref90_viridae_embl_hosts_pruned_metadata_species_vertebrates_w_seq_non_idv_t0.01_c5.csv" ]
  # seeds to split the files into training and testing
  # if provided, the number of seeds must match the number of iterations configured in classification_settings (n_iterations)
  split_seeds: [ 12612648, 31062180, 48918293, 55631155, 79221635 ]

sequence_settings:
    batch_size: 32
    id_col: "uniref90_id"
    sequence_col: "seq"
    max_sequence_length: 1366 # 6630 # 1024 # 1115
    truncate: True
    pad_token_val: 0
    feature_type: "token"  # supported values 'kmer', 'cgr', 'token'

pre_train_settings:
  model_name: "masked_language_modeling"
  model_path: "output/raw/uniref90/20231115/pre_training/mlm/transformer_encoder-l_6-h_8-lr1e-4-mlm_itr0.pth"
  encoder_settings:
    model_name: "transformer_encoder-l_6-h_8-lr1e-4-mlm"
    n_heads: 8
    depth: 6
    input_dim: 512 # input embedding dimension
    hidden_dim: 1024
    n_tokens: 26

fine_tune_settings:
  experiment: "fine_tune_model"
  n_iterations: 5
  split_input: False
  train_proportion: 0.01
  classification_type: "multi"

  training_settings:
    n_epochs_freeze: 0
    n_epochs_unfreeze: 50
    max_lr: 1e-4
    pct_start: 0.10
    div_factor: 25.0
    final_div_factor: 10000.0

  label_settings:
    label_col: "virus_host_name"
    exclude_labels: [ "nan" ]
    label_groupings:
      "Human": [ "Homo sapiens" ]
      "Pig": [ "Sus scrofa" ]
      "Capybara": [ "Hydrochoerus hydrochaeris" ]
      "Himalayan marmot": [ "Marmota himalayana" ]
      "Red junglefowl": [ "Gallus gallus" ]
#      "Common carp": [ "Cyprinus carpio" ]
#      "South Island robin": [ "Petroica australis" ]
#      "Cat": [ "Felis catus" ]
#      "Sonoran Desert tortoise": [ "Gopherus morafkai" ]
#      "Brush mouse": [ "Peromyscus boylii" ]
#      "Yellow-bellied marmot": [ "Marmota flaviventris" ]
#      "Cattle": [ "Bos taurus" ]
#      "Big brown bat": [ "Eptesicus fuscus" ]

  task_settings:
    - name: "host_prediction_fnn_2l_d1024_lr1e-4"
      active: True
      mode: "test" # supported values: train, test
      fine_tuned_model_path: "output/raw/uniref90_embl_vertebrates_non_idv_t0.01_c5/20240307/host_multi/fine_tuning/host_prediction_fnn_2l_d1024_lr1e-4_fe20_ufe30_itr0.pth"
      loss: "FocalLoss"
      depth: 2
      n_classes: 5
      input_dim: 512 # input embedding dimension
      hidden_dim: 1024

output_settings:
  output_dir: "output"
  results_dir: "raw"
  sub_dir: "uniref90_embl_vertebrates_idv/20240401/host_multi/fine_tuning"
  prefix: "mlm_tfenc_l6_h8_lr1e-4_uniref90viridae_msl1366" # default: none; default file name = kmer_k<k>_lr_c<c>_<label>_<type>_tr<train_proportion>_n<n_iterations>_<output_prefix>_output.csv
