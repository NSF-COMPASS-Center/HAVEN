# Input Settings: initialize base input folder names,
# dataset collections, and algorithms to run over
input_settings:

    # Denotes a list of datasets, each with the following parameters:
    #   name: Name of the dataset. May be used in logging or other
    #       messages written during execution
    #
    #   path: Relative path to the protein file
    datasets:
        "viprbrc_protein":
            path: "data/hep/hep-manual-692853522-0.5.fasta"
            rowNames: ["Accession", "Protein", "Host", "Genotype"]

    # Denotes a list of models to train/run
    models:
        # Classical bilstm language model from https://doi.org/10.1126/science.abd7331
        bilstm:
            active: True
            should_train: True
            n_hidden: 2
            seed: 692853522
            checkpoint: #"target/hep/checkpoints/bilstm/r1/bilstm_host_512-11.hdf5"
            epochs: 12

            # Same model as above, but different last layer classifier for transfer learning
            # Classifies 1/0 human/non-human
            bilstm_host:
                active: false
                epochs: 2
                n_hidden: 2
                embedding_dim: 20
                embed_targets: ["Protein", "Host", "Genotype"]
                embedding_cache: True
                should_train: False
                should_embed: False
                should_visualize_data: False
                train_split: 0
                batch_size: 64
                inf_batch_size: 144
                should_test: True
                transfer_learning: False
                checkpoint: "target/hep/checkpoints/bilstm_host/bilstm_host_512-195.hdf5"
                targetKey: "Host"
                # e.g, the output heads would be ["Human", "Non-Human"]
                targetNames: ["Human"]

# Output Settings: initialize base output folder names
output_settings:
    # Base output directory
    namespace: "hep"
    output_dir: "Output"
    model_name: "hepBase-692853522"

