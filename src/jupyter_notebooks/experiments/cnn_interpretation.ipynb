{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12e40648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, accuracy_score, f1_score, auc, precision_recall_curve\n",
    "from statistics import mean\n",
    "from captum.attr import Saliency, DeepLift, IntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf406038",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a6fe47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\",\n",
    "           \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "max_lr = 1e-3\n",
    "n_epochs = 1\n",
    "model_name = \"CNN-2D\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df50933",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ceb1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "train_dataset_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                                   batch_size=batch_size, \n",
    "                                                   shuffle=True)                                   \n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "test_dataset_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                                  batch_size=batch_size, \n",
    "                                                  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848e3b8",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73556a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 6, 5, stride=1, padding=\"same\")\n",
    "        self.conv_2 = nn.Conv2d(6, 16, 5, stride=1, padding=\"same\")\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.linear_1 = nn.Linear(16 * 8 * 8, 120)\n",
    "        self.linear_2 = nn.Linear(120, 84)\n",
    "        self.linear_3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.conv_1(x)))\n",
    "        x = self.maxpool(F.relu(self.conv_2(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimension except the first one which corresponds to batch\n",
    "        \n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = F.relu(self.linear_2(x))\n",
    "        \n",
    "        x = self.linear_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d65bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d923405",
   "metadata": {},
   "source": [
    "### Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d3d0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=max_lr)\n",
    "lr_scheduler = OneCycleLR(\n",
    "                    optimizer=optimizer,\n",
    "                    max_lr=max_lr,\n",
    "                    epochs=n_epochs,\n",
    "                    steps_per_epoch=len(train_dataset_loader),\n",
    "                    pct_start=0.1,\n",
    "                    anneal_strategy='cos',\n",
    "                    div_factor=25.0,\n",
    "                    final_div_factor=10000.0)\n",
    "tbw = SummaryWriter() # tensorboard summary writer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0236d39b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126d9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train_iter = 0\n",
    "    model.val_iter = 0\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for _, data in enumerate(pbar := tqdm.tqdm(train_dataset_loader, 0)):\n",
    "            model.train_iter += 1 \n",
    "            # get input and labels; data is a list of [(inputs, labels)]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            # loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward propagate loss\n",
    "            loss.backward()\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            # training_loss\n",
    "            train_loss = loss.item()\n",
    "            # tensorboard + logs\n",
    "            tbw.add_scalar(f\"{model_name}/training-loss\", float(train_loss), model.train_iter)\n",
    "            pbar.set_description(f\"{model_name}/training-loss={train_loss}, steps={model.train_iter}, epoch={epoch+1}\")\n",
    "            \n",
    "        validate(model, epoch)\n",
    "        \n",
    "    return model, validate(model, epoch)\n",
    "    \n",
    "def validate(model, epoch=0):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for _, data in enumerate(pbar := tqdm.tqdm(test_dataset_loader, 0)):\n",
    "            # get input and labels; data is a list of [(inputs, labels)]\n",
    "            inputs, labels = data\n",
    "\n",
    "            output = model(inputs)\n",
    "            # loss\n",
    "            loss = criterion(output, labels)\n",
    "            curr_val_loss = loss.item()\n",
    "            model.val_iter += 1\n",
    "\n",
    "            # tensorboard + logs\n",
    "            tbw.add_scalar(f\"{model_name}/validation-loss\", float(curr_val_loss), model.val_iter)\n",
    "            pbar.set_description(f\"{model_name}/validation-loss={curr_val_loss}, steps={model.val_iter}, epoch={epoch+1}\")\n",
    "\n",
    "            # to get probabilities of the output\n",
    "            output = F.softmax(output, dim=-1)\n",
    "            result_df = pd.DataFrame(output.cpu().numpy())\n",
    "            result_df[\"y_true\"] = labels.cpu().numpy()\n",
    "            results.append(result_df)\n",
    "    \n",
    "    return pd.concat(results, ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f3d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-2D/training-loss=2.3232076168060303, steps=782, epoch=1: 100%|████████████████████████| 782/782 [02:04<00:00,  6.26it/s]\n",
      "CNN-2D/validation-loss=2.29150128364563, steps=157, epoch=1: 100%|████████████████████████| 157/157 [00:10<00:00, 15.36it/s]\n",
      "CNN-2D/validation-loss=2.29150128364563, steps=314, epoch=1: 100%|████████████████████████| 157/157 [00:10<00:00, 15.32it/s]\n"
     ]
    }
   ],
   "source": [
    "model, results = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcd2e337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.099236</td>\n",
       "      <td>0.094794</td>\n",
       "      <td>0.093328</td>\n",
       "      <td>0.099401</td>\n",
       "      <td>0.101005</td>\n",
       "      <td>0.100911</td>\n",
       "      <td>0.108543</td>\n",
       "      <td>0.102514</td>\n",
       "      <td>0.105266</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.099690</td>\n",
       "      <td>0.094495</td>\n",
       "      <td>0.092473</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.100804</td>\n",
       "      <td>0.101270</td>\n",
       "      <td>0.108735</td>\n",
       "      <td>0.102835</td>\n",
       "      <td>0.106296</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.099770</td>\n",
       "      <td>0.094113</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.099116</td>\n",
       "      <td>0.100784</td>\n",
       "      <td>0.101022</td>\n",
       "      <td>0.108739</td>\n",
       "      <td>0.102015</td>\n",
       "      <td>0.106203</td>\n",
       "      <td>0.095062</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100045</td>\n",
       "      <td>0.094511</td>\n",
       "      <td>0.093239</td>\n",
       "      <td>0.098933</td>\n",
       "      <td>0.101167</td>\n",
       "      <td>0.100464</td>\n",
       "      <td>0.108663</td>\n",
       "      <td>0.102330</td>\n",
       "      <td>0.105852</td>\n",
       "      <td>0.094796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.098358</td>\n",
       "      <td>0.094266</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>0.099647</td>\n",
       "      <td>0.101853</td>\n",
       "      <td>0.100885</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>0.104864</td>\n",
       "      <td>0.094074</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.099488</td>\n",
       "      <td>0.094419</td>\n",
       "      <td>0.093041</td>\n",
       "      <td>0.099210</td>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.101254</td>\n",
       "      <td>0.109353</td>\n",
       "      <td>0.103042</td>\n",
       "      <td>0.105253</td>\n",
       "      <td>0.093771</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.098113</td>\n",
       "      <td>0.094693</td>\n",
       "      <td>0.092736</td>\n",
       "      <td>0.099841</td>\n",
       "      <td>0.101368</td>\n",
       "      <td>0.100895</td>\n",
       "      <td>0.109866</td>\n",
       "      <td>0.103509</td>\n",
       "      <td>0.104664</td>\n",
       "      <td>0.094315</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.096948</td>\n",
       "      <td>0.094890</td>\n",
       "      <td>0.092133</td>\n",
       "      <td>0.100815</td>\n",
       "      <td>0.100713</td>\n",
       "      <td>0.102226</td>\n",
       "      <td>0.109501</td>\n",
       "      <td>0.104584</td>\n",
       "      <td>0.103807</td>\n",
       "      <td>0.094383</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.097994</td>\n",
       "      <td>0.094658</td>\n",
       "      <td>0.093248</td>\n",
       "      <td>0.100330</td>\n",
       "      <td>0.100930</td>\n",
       "      <td>0.101213</td>\n",
       "      <td>0.109010</td>\n",
       "      <td>0.103006</td>\n",
       "      <td>0.104937</td>\n",
       "      <td>0.094674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.098464</td>\n",
       "      <td>0.094396</td>\n",
       "      <td>0.093439</td>\n",
       "      <td>0.100148</td>\n",
       "      <td>0.101485</td>\n",
       "      <td>0.101029</td>\n",
       "      <td>0.108939</td>\n",
       "      <td>0.103417</td>\n",
       "      <td>0.104527</td>\n",
       "      <td>0.094156</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.099236  0.094794  0.093328  0.099401  0.101005  0.100911  0.108543   \n",
       "1     0.099690  0.094495  0.092473  0.098701  0.100804  0.101270  0.108735   \n",
       "2     0.099770  0.094113  0.093175  0.099116  0.100784  0.101022  0.108739   \n",
       "3     0.100045  0.094511  0.093239  0.098933  0.101167  0.100464  0.108663   \n",
       "4     0.098358  0.094266  0.093771  0.099647  0.101853  0.100885  0.108963   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.099488  0.094419  0.093041  0.099210  0.101168  0.101254  0.109353   \n",
       "9996  0.098113  0.094693  0.092736  0.099841  0.101368  0.100895  0.109866   \n",
       "9997  0.096948  0.094890  0.092133  0.100815  0.100713  0.102226  0.109501   \n",
       "9998  0.097994  0.094658  0.093248  0.100330  0.100930  0.101213  0.109010   \n",
       "9999  0.098464  0.094396  0.093439  0.100148  0.101485  0.101029  0.108939   \n",
       "\n",
       "             7         8         9  y_true  \n",
       "0     0.102514  0.105266  0.095001       3  \n",
       "1     0.102835  0.106296  0.094700       8  \n",
       "2     0.102015  0.106203  0.095062       8  \n",
       "3     0.102330  0.105852  0.094796       0  \n",
       "4     0.103319  0.104864  0.094074       6  \n",
       "...        ...       ...       ...     ...  \n",
       "9995  0.103042  0.105253  0.093771       8  \n",
       "9996  0.103509  0.104664  0.094315       3  \n",
       "9997  0.104584  0.103807  0.094383       5  \n",
       "9998  0.103006  0.104937  0.094674       1  \n",
       "9999  0.103417  0.104527  0.094156       7  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46b528b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC for class 0 = 0.25787064348973504\n",
      "AUPRC for class 1 = 0.1701077173030176\n",
      "AUPRC for class 2 = 0.1736992011648282\n",
      "AUPRC for class 3 = 0.12486837002079033\n",
      "AUPRC for class 4 = 0.17783742889893367\n",
      "AUPRC for class 5 = 0.10462516444183038\n",
      "AUPRC for class 6 = 0.14732852023495913\n",
      "AUPRC for class 7 = 0.1346943178682629\n",
      "AUPRC for class 8 = 0.26444634546603746\n",
      "AUPRC for class 9 = 0.14328781051171552\n",
      "Macro AUPRC = 0.16987655194001103\n"
     ]
    }
   ],
   "source": [
    "auprcs = []\n",
    "for i in range(10):\n",
    "    precision, recall, _ = precision_recall_curve(y_true=results[\"y_true\"].values, probas_pred=results[i].values, pos_label=i)\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC for class {i} = {auprc}\")\n",
    "    auprcs.append(auprc)\n",
    "\n",
    "macro_auprc = mean(auprcs)\n",
    "print(f\"Macro AUPRC = {macro_auprc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e61be75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = Saliency(model)\n",
    "inputs = next(iter(test_dataset_loader))[0][0].unsqueeze(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be4d104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "attribution = dl.attribute(inputs, target=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32dc7db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81442bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
