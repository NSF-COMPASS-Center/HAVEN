{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd64c278",
   "metadata": {},
   "source": [
    "## Interpretation of TF models trained on UniRef90 dataset for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0a7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Dev\\\\git\\\\zoonosis\\\\src\\\\jupyter_notebooks\\\\interpretation',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\python39.zip',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages\\\\locket-0.2.1-py3.9.egg',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\bless\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\bless\\\\.ipython',\n",
       " 'C:\\\\Dev\\\\git\\\\zoonosis\\\\src\\\\jupyter_notebooks\\\\interpretation\\\\..\\\\..',\n",
       " 'C:\\\\Dev\\\\git\\\\zoonosis\\\\src\\\\jupyter_notebooks\\\\interpretation\\\\..']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256b5134",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10216/34756804.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\git\\zoonosis\\src\\jupyter_notebooks\\interpretation\\..\\..\\prediction\\models\\nlp\\transformer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbeddingLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConvolutionEmbeddingLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEncoderLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from prediction.models.nlp import transformer\n",
    "from src.utils import utils, nn_utils\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/grads/blessyantony/dev/git/zoonosis/input/data/uniref90/splits/s79221635\"\n",
    "train_file_names = [\"uniref90_final.csv_tr0.8_train.csv\"]\n",
    "test_file_names = [\"uniref90_final.csv_tr0.8_test.csv\"]\n",
    "\n",
    "label_groupings = {\"Human\": [ \"Homo sapiens\" ],\n",
    "                  \"Desert warthog\": [ \"Phacochoerus aethiopicus\" ],\n",
    "                  \"Lesser bandicoot rat\": [ \"Bandicota bengalensis\" ],\n",
    "                  \"Horse\": [ \"Equus caballus\" ],\n",
    "                  \"Goat\": [ \"Capra hircus\" ],\n",
    "                  \"Red junglefowl\": [ \"Gallus gallus\" ],\n",
    "                  \"Wood mouse\": [ \"Apodemus sylvaticus\" ],\n",
    "                  \"Cattle\": [ \"Bos taurus\" ],\n",
    "                  \"Others\": [ \"*\" ]}\n",
    "host_classes = [\"Homo sapiens\",  \"Phacochoerus aethiopicus\",    \"Bandicota bengalensis\",     \"Equus caballus\",   \"Capra hircus\", \n",
    "                \"Gallus gallus\",   \"Apodemus sylvaticus\",     \"Bos taurus\",  \"Others\"]\n",
    "\n",
    "amino_acid_idx_map = {'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5,\n",
    "                  'Q': 6, 'E': 7, 'G': 8, 'H': 9, 'I': 10,\n",
    "                  'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15,\n",
    "                  'O': 16, 'S': 17, 'U': 18, 'T': 19, 'W': 20,\n",
    "                  'Y': 21, 'V': 22, 'B': 23, 'Z': 24, 'X': 25,\n",
    "                  'J': 26}\n",
    "idx_amino_acid_map = {v:k for k,v in amino_acid_idx_map.items()}\n",
    "\n",
    "train_sequence_settings =  {\n",
    "    \"sequence_col\": \"seq\",\n",
    "    \"batch_size\": 8,\n",
    "    \"max_sequence_length\": 1024,\n",
    "    \"pad_sequence_val\": 0,\n",
    "    \"truncate\": True\n",
    "}\n",
    "\n",
    "test_sequence_settings =  train_sequence_settings.copy()\n",
    "test_sequence_settings[\"batch_size\"] = 1\n",
    "\n",
    "label_settings = {\n",
    "    \"label_col\": \"virus_host_name\",\n",
    "    \"exclude_labels\": [ \"nan\"],\n",
    "    \"label_groupings\":  label_groupings\n",
    "}\n",
    "\n",
    "model = {\n",
    "    \"max_seq_len\": 1024,\n",
    "    \"loss\": \"CrossEntropyLoss\",\n",
    "    \"with_convolution\": False,\n",
    "    \"n_heads\": 8,\n",
    "    \"depth\": 6,\n",
    "    \"n_tokens\": 27,\n",
    "    \"n_classes\": 9,\n",
    "    \"n_epochs\": 10,\n",
    "    \"dim\": 512,\n",
    "    \"weight_initialization\": \"normal\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4b303",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc7319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(input_dir, input_file_names, sequence_settings):\n",
    "    df = utils.read_dataset(input_dir, input_file_names, cols=[sequence_settings[\"sequence_col\"], label_settings[\"label_col\"]])\n",
    "    df, index_label_map = utils.transform_labels(df, label_settings, classification_type=\"multi\")\n",
    "    dataset_loader = nn_utils.get_dataset_loader(df, sequence_settings, label_settings[\"label_col\"])\n",
    "    return index_label_map, dataset_loader\n",
    "\n",
    "def load_dataset_with_df(df, sequence_settings):\n",
    "    df = df[[sequence_settings[\"sequence_col\"], label_settings[\"label_col\"]]]\n",
    "    df, index_label_map = utils.transform_labels(df, label_settings, classification_type=\"multi\")\n",
    "    dataset_loader = nn_utils.get_dataset_loader(df, sequence_settings, label_settings[\"label_col\"])\n",
    "    return index_label_map, dataset_loader\n",
    "\n",
    "def print_dataset_loader(dataset_loader):\n",
    "    sequence, label = next(iter(dataset_loader))\n",
    "    print(sequence.shape)\n",
    "    print(sequence)\n",
    "    print(label.shape)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055848d",
   "metadata": {},
   "source": [
    "### Training-based interpretation\n",
    "#### Encoding visualization - all viruses, all hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4285e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dataset_representations(nlp_model, dataset_loader):\n",
    "    nlp_model.eval()\n",
    "    seq_dfs = []\n",
    "    for _, record in enumerate(dataset_loader):\n",
    "        seq, label = record\n",
    "        output = nlp_model(seq)\n",
    "        seq_encoding = nlp_model.encoder.encoding\n",
    "        # embedding = value for each dimension = mean of the dimensional values of all tokens in the input sequence\n",
    "        seq_encoding = torch.mean(seq_encoding, dim=1, keepdim=True)\n",
    "        seq_df = pd.DataFrame(seq_encoding.squeeze().cpu().detach().numpy())\n",
    "        seq_df[\"label\"] = label.squeeze().cpu().detach().numpy()\n",
    "        seq_dfs.append(seq_df)\n",
    "    df = pd.concat(seq_dfs)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_dataset(rep_df):\n",
    "    columns = rep_df.columns\n",
    "    print(columns)\n",
    "    X = rep_df[range(512)]\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, init=\"pca\", learning_rate=\"auto\").fit(X)\n",
    "    X_emb = pd.DataFrame(tsne_model.fit_transform(X))\n",
    "    print(X_emb.shape)\n",
    "    print(X_emb)\n",
    "    X_emb[\"label\"] = rep_df[\"label\"].values\n",
    "    return tsne_model, X_emb\n",
    "    \n",
    "def visualize_prediction(nlp_model, seq, label, rep_df):\n",
    "    nlp_model.eval()\n",
    "    output = nlp_model(seq)\n",
    "    seq_encoding = nlp_model.encoder.encoding\n",
    "    seq_encoding = torch.mean(seq_encoding, dim=1, keepdim=True)\n",
    "\n",
    "    seq_df = pd.DataFrame(seq_encoding.squeeze(1).cpu().detach().numpy())\n",
    "    seq_df[\"label\"] = label.squeeze().cpu().detach().numpy()\n",
    "    sample_pred = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "    print(f\"Label {label} = {index_label_map[label.item()]}\")\n",
    "    sample_pred_mapped = index_label_map[sample_pred.item()]\n",
    "    print(f\"Prediction {sample_pred}= {sample_pred_mapped}\")\n",
    "    seq_df[\"label\"] = \"prediction-\" + sample_pred_mapped\n",
    "    \n",
    "    rep_df_copy = rep_df.copy()\n",
    "    rep_df_copy[\"label\"] = rep_df[\"label\"].map(index_label_map)\n",
    "    rep_df_copy = rep_df_copy[rep_df_copy[\"label\"] != \"Others\"]\n",
    "    rep_seq_df = pd.concat([rep_df_copy, seq_df])\n",
    "    print(f\"rep_seq_df shape = {rep_seq_df.shape}\")\n",
    "    X = rep_seq_df[range(512)]\n",
    "    print(f\"X shape = {X.shape}\")\n",
    "    \n",
    "    tsne_model = TSNE(n_components=2, verbose=1, init=\"pca\", learning_rate=\"auto\").fit(X)\n",
    "    X_emb = pd.DataFrame(tsne_model.fit_transform(X))\n",
    "    print(f\"X_emb shape = {X_emb.shape}\")\n",
    "    X_emb[\"label\"] = rep_seq_df[\"label\"].values\n",
    "    print(f\"X_emb shape = {X_emb.shape}\")\n",
    "    sns.scatterplot(data = X_emb, x=0, y=1, hue=\"label\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6faf24",
   "metadata": {},
   "source": [
    "### Testing-based interpretation\n",
    "#### Attention based interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b263cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_attn_values(nlp_model):\n",
    "    attn_values = nlp_model.encoder.layers[5].self_attn.self_attn.squeeze()\n",
    "    return torch.mean(attn_values, dim=0)\n",
    "\n",
    "\n",
    "def plot_mean_attention_values(x, seq=None, seq_len=None):\n",
    "    ticklabels = seq.cpu().detach().numpy().squeeze()[:seq_len]\n",
    "    ticklabels_mapped = [idx_amino_acid_map[x] for x in ticklabels]\n",
    "\n",
    "    plt.rcParams['xtick.labelsize'] = 5\n",
    "    plt.rcParams['ytick.labelsize'] = 5\n",
    "    plt.figure(figsize=(12,12))\n",
    "    data = x.cpu().detach().numpy()\n",
    "    \n",
    "    sns.heatmap(data=data[:seq_len, :seq_len], xticklabels=ticklabels_mapped, yticklabels=ticklabels_mapped)\n",
    "    #plt.xticks(rotation=20)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_mean_of_mean_attention_values(x, seq=None, seq_len=None, seq_max_length=None):\n",
    "    tokens = seq.cpu().detach().numpy().squeeze()\n",
    "    \n",
    "    x = torch.mean(x, dim=0)\n",
    "    df = pd.DataFrame({\"tokens\": tokens, \"attn_vals\": x.cpu().detach().numpy(), \"pos\": range(seq_max_length)})\n",
    "    df[\"tokens\"] = df[\"tokens\"].map(idx_amino_acid_map)\n",
    "    df = df.dropna()\n",
    "    sorted_df = df.sort_values(by=\"attn_vals\", ascending=False).head(10)\n",
    "    print(\"Top 10 tokens + positions with highest attention values for the whole sequence\")\n",
    "    print(sorted_df.head(10))\n",
    "    plt.rcParams['xtick.labelsize'] = 8\n",
    "    plt.rcParams['ytick.labelsize'] = 8\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.scatterplot(data=df, x=\"pos\", y=\"attn_vals\", hue=\"tokens\")\n",
    "    plt.show()\n",
    "    \n",
    "def analyze_attention_of_prediction(nlp_model, sample_seq, sample_label, seq_max_length):\n",
    "    # sample_seq = sample_seq.unsqueeze(0)\n",
    "    seq_len= torch.count_nonzero(sample_seq)\n",
    "    print(sample_seq.shape)\n",
    "    print(f\"seq_len = {seq_len}\")\n",
    "    \n",
    "    nlp_model.eval()\n",
    "    output = nlp_model(sample_seq)\n",
    "    sample_pred = torch.argmax(F.softmax(nlp_model(sample_seq), dim=1), dim=1)\n",
    "    print(f\"Label = {index_label_map[sample_label.item()]}\")\n",
    "    print(f\"Prediction = {index_label_map[sample_pred.item()]}\")\n",
    "    mean_attn_values = compute_mean_attn_values(nlp_model)\n",
    "\n",
    "    plot_mean_attention_values(mean_attn_values, seq=sample_seq, seq_len=seq_len)\n",
    "    plot_mean_of_mean_attention_values(mean_attn_values, seq=sample_seq, seq_len=seq_len, seq_max_length=seq_max_length)\n",
    "    \n",
    "def analyze_attention_of_df(nlp_model, dataset_loader, seq_max_length):\n",
    "    attn_dfs = []\n",
    "    max_seq_len_actual = 0\n",
    "    for _, record in enumerate(dataset_loader):\n",
    "        seq, label = record\n",
    "        seq_len = torch.count_nonzero(seq).item()\n",
    "        if seq_len > max_seq_len_actual:\n",
    "            max_seq_len_actual = seq_len\n",
    "        nlp_model(seq)\n",
    "        mean_attn_values = compute_mean_attn_values(nlp_model)\n",
    "        mean_of_mean = torch.mean(mean_attn_values, dim=0, keepdim=True)\n",
    "        attn_dfs.append(mean_of_mean.cpu().detach().numpy())\n",
    "    print(\"max_seq_len_actual = \", max_seq_len_actual)\n",
    "    attn_df = np.concatenate(attn_dfs, axis=0)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.heatmap(data=attn_df[:,:max_seq_len_actual])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bebb65",
   "metadata": {},
   "source": [
    " ### Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591470ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_model(model, train_dataset_loader, test_dataset_loader, seq, label, seq_max_length, viz_train=False, viz_test=False):\n",
    "    if viz_train:\n",
    "        train_rep_df = compute_dataset_representations(model, train_dataset_loader)\n",
    "        visualize_prediction(model, seq, label, train_rep_df)\n",
    "    if viz_test:\n",
    "        test_rep_df = compute_dataset_representations(model, test_dataset_loader)\n",
    "        visualize_dataset(test_rep_df)\n",
    "    \n",
    "    \n",
    "    analyze_attention_of_prediction(model, seq, label, seq_max_length)\n",
    "    \n",
    "    analyze_attention_of_df(model, test_dataset_loader, seq_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4bb0f",
   "metadata": {},
   "source": [
    "#### UniRef90 Datasets\n",
    "19k\n",
    "all viruses, all hosts, all proteins, without duplicates and single hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_map, train_dataset_loader = load_dataset(input_dir, train_file_names, train_sequence_settings)\n",
    "print_dataset_loader(train_dataset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b0e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_label_map, test_dataset_loader = load_dataset(input_dir, test_file_names, test_sequence_settings)\n",
    "print_dataset_loader(test_dataset_loader)\n",
    "# Random seq, label from test_dataset_loader\n",
    "test_seq, test_label = next(iter(test_dataset_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427e2adb",
   "metadata": {},
   "source": [
    "#### UniProtKB Coronavirus only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c949e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref90_coronaviruses_df = pd.read_csv(\"/home/grads/blessyantony/dev/git/zoonosis/input/data/coronaviridae/coronaviridae_top_7_hosts.csv\")\n",
    "uniref90_coronaviruses_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4440ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref90_coronaviruses_df[\"virus_host\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23898e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref90_coronaviruses_humans_df = uniref90_coronaviruses_df[uniref90_coronaviruses_df[\"virus_host\"] == \"Homo sapiens (Human) [TaxID: 9606]\"]\n",
    "print(uniref90_coronaviruses_humans_df.shape)\n",
    "uniref90_coronaviruses_humans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c49ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniref90_coronaviruses_humans_df[\"virus_host\"] = \"Homo sapiens\"\n",
    "uniref90_coronaviruses_humans_df.rename(columns={\"virus_host\": \"virus_host_name\"}, inplace=True)\n",
    "uniref90_coronaviruses_humans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(uniref90_coronaviruses_humans_df[\"seq_len\"])\n",
    "print(f\"min seq len = {min(uniref90_coronaviruses_humans_df['seq_len'])}\")\n",
    "print(f\"max seq len = {max(uniref90_coronaviruses_humans_df['seq_len'])}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f371b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, coronavirus_dataset_loader = load_dataset_with_df(uniref90_coronaviruses_humans_df, test_sequence_settings)\n",
    "print_dataset_loader(coronavirus_dataset_loader)\n",
    "# Random seq, label from coronavirus_dataset_loader\n",
    "coronavirus_seq, coronavirus_label = next(iter(coronavirus_dataset_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab719dd1",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd808d29",
   "metadata": {},
   "source": [
    "#### Model: TF - PosEmb_SINCOS - MSL_1024 - d_512\n",
    "#### Manual Seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32b93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/grads/blessyantony/dev/git/zoonosis/output/raw/uniref90/20230531/host_multi-seed0/transformer-crossentropy_itr4.pth\"\n",
    "\n",
    "nlp_model = transformer.get_transformer_model(model)\n",
    "nlp_model.load_state_dict(torch.load(model_path))\n",
    "nlp_model = nlp_model.to(nn_utils.get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, test_dataset_loader, test_seq, test_label, seq_max_length=1024, viz_train=True, viz_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e749ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, coronavirus_dataset_loader, coronavirus_seq, coronavirus_label, seq_max_length=1024, viz_train=False, viz_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f6aaf",
   "metadata": {},
   "source": [
    "#### Model: TF - PosEmb_SINCOS - MSL_1024 - d_512\n",
    "#### Manual Seed = 170638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bf5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/grads/blessyantony/dev/git/zoonosis/output/raw/uniref90/20230531/host_multi-seed170638/transformer-crossentropy_itr4.pth\"\n",
    "\n",
    "nlp_model = transformer.get_transformer_model(model)\n",
    "nlp_model.load_state_dict(torch.load(model_path))\n",
    "nlp_model = nlp_model.to(nn_utils.get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c9b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, test_dataset_loader, test_seq, test_label, seq_max_length=1024, viz_train=True, viz_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e48bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, coronavirus_dataset_loader, coronavirus_seq, coronavirus_label, seq_max_length=1024, viz_train=False, viz_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee43749",
   "metadata": {},
   "source": [
    "#### Model: TF - PosEmb_SINCOS - MSL_1024 - d_512\n",
    "#### Manual Seed = 745540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a802cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/grads/blessyantony/dev/git/zoonosis/output/raw/uniref90/20230531/host_multi-seed745540/transformer-crossentropy_itr4.pth\"\n",
    "\n",
    "nlp_model = transformer.get_transformer_model(model)\n",
    "nlp_model.load_state_dict(torch.load(model_path))\n",
    "nlp_model = nlp_model.to(nn_utils.get_device())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d000e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, test_dataset_loader, test_seq, test_label, seq_max_length=1024, viz_train=True, viz_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258500c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(nlp_model, train_dataset_loader, coronavirus_dataset_loader, coronavirus_seq, coronavirus_label, seq_max_length=1024, viz_train=False, viz_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import motifs\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "for s in uniref90_coronaviruses_humans_df[\"seq\"]:\n",
    "    if len(s) >= 900:\n",
    "        instances.append(Seq(s[:900]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e153203",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = motifs.create(instances, alphabet=generic_protein)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
