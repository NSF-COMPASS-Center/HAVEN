{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c9e9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/grads/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/experiments',\n",
       " '/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python310.zip',\n",
       " '/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python3.10',\n",
       " '/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python3.10/site-packages',\n",
       " '/home/grads/blessyantony/anaconda3/envs/zoonosis/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-linux-x86_64.egg',\n",
       " '/home/grads/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/experiments/../../..',\n",
       " '/home/grads/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/experiments/../..',\n",
       " '/home/grads/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/experiments/..']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3d5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torchvision.datasets\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Conv2d\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "from utils import utils, nn_utils\n",
    "from utils.early_stopping import EarlyStopping\n",
    "from sklearn.metrics import roc_curve, accuracy_score, f1_score, auc, precision_recall_curve\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b7f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2D_Model(nn.Module):\n",
    "    def __init__(self, n_classes, N, n_filters, kernel_size, stride, img_size):\n",
    "        super(CNN_2D_Model, self).__init__()\n",
    "        # padding: same ensures the output has the same size as the input\n",
    "        self.conv2d = Conv2d(in_channels=3,\n",
    "                             out_channels=n_filters,\n",
    "                             kernel_size=kernel_size,\n",
    "                             stride=stride,\n",
    "                             padding=\"same\")\n",
    "        self.conv2d_hidden = Conv2d(in_channels=n_filters,\n",
    "                                    out_channels=n_filters,\n",
    "                                    kernel_size=kernel_size,\n",
    "                                    stride=stride,\n",
    "                                    padding=\"same\")\n",
    "        # intermediate hidden layers (number = N-1): hidden_dim --> hidden_dim\n",
    "        # N-1 because we already have one layer converting input_dim --> hidden_dim\n",
    "        self.conv2d_hidden_layers = nn_utils.create_clones(self.conv2d_hidden, N - 1)\n",
    "        self.linear = nn.Linear(img_size * img_size * n_filters, n_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv2d(X))\n",
    "        for conv2d_hidden_layer in self.conv2d_hidden_layers:\n",
    "            X = F.relu(conv2d_hidden_layer(X))\n",
    "\n",
    "        # aggregate the embeddings from cnn\n",
    "        # mean of the representations of all tokens\n",
    "        self.cnn_emb = torch.flatten(X, 1)  # flatten all dimensions except batch\n",
    "        y = self.linear(self.cnn_emb)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "def get_cnn_model(model):\n",
    "    cnn_model = CNN_2D_Model(n_classes=model[\"n_classes\"],\n",
    "                             N=model[\"depth\"],\n",
    "                             n_filters=model[\"n_filters\"],\n",
    "                             kernel_size=model[\"kernel_size\"],\n",
    "                             stride=model[\"stride\"],\n",
    "                             img_size=model[\"img_size\"])\n",
    "\n",
    "    print(cnn_model)\n",
    "    print(\"Number of parameters = \", sum(p.numel() for p in cnn_model.parameters() if p.requires_grad))\n",
    "    return cnn_model.to(nn_utils.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e8238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, train_dataset_loader, test_dataset_loader, loss, n_epochs, model_name, mode):\n",
    "    tbw = SummaryWriter()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    max_lr = 1e-3\n",
    "    lr_scheduler = OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=max_lr,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch=len(train_dataset_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=25.0,\n",
    "        final_div_factor=10000.0)\n",
    "    early_stopper = EarlyStopping(patience=10, min_delta=0)\n",
    "    model.train_iter = 0\n",
    "    model.test_iter = 0\n",
    "\n",
    "    if mode == \"train\":\n",
    "        # train the model only if set to train mode\n",
    "        for e in range(n_epochs):\n",
    "            model = run_epoch(model, train_dataset_loader, test_dataset_loader, criterion, optimizer,\n",
    "                              lr_scheduler, early_stopper, tbw, model_name, e, max_lr)\n",
    "            # check if early stopping condition was satisfied and stop accordingly\n",
    "            if early_stopper.early_stop:\n",
    "                print(\"Breaking off training loop due to early stop\")\n",
    "                break\n",
    "\n",
    "    result_df, _ = evaluate_model(model, test_dataset_loader, criterion, tbw, model_name, epoch=None, max_lr=max_lr, log_loss=False), model\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def run_epoch(model, train_dataset_loader, test_dataset_loader, criterion, optimizer, lr_scheduler, early_stopper, tbw, model_name,\n",
    "              epoch, max_lr):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for _, record in enumerate(pbar := tqdm.tqdm(train_dataset_loader)):\n",
    "        input, label = record\n",
    "        input = input.to(nn_utils.get_device())\n",
    "        label = label.to(nn_utils.get_device())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(input)\n",
    "        output = output.to(nn_utils.get_device())\n",
    "\n",
    "        loss = criterion(output, label.long())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        model.train_iter += 1\n",
    "        curr_lr = lr_scheduler.get_last_lr()[0]\n",
    "        train_loss = loss.item()\n",
    "        tbw.add_scalar(f\"{model_name}-max_lr{max_lr}/learning-rate\", float(curr_lr), model.train_iter)\n",
    "        tbw.add_scalar(f\"{model_name}-max_lr{max_lr}/training-loss\", float(train_loss), model.train_iter)\n",
    "        pbar.set_description(\n",
    "            f\"{model_name}/training-loss = {float(train_loss)}, model.n_iter={model.train_iter}, epoch={epoch + 1}\")\n",
    "\n",
    "    # Testing\n",
    "    _, val_loss = evaluate_model(model, test_dataset_loader, criterion, tbw, model_name, epoch, max_lr, log_loss=True)\n",
    "    early_stopper(val_loss)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dataset_loader, criterion, tbw, model_name, epoch, max_lr, log_loss=False):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        results = []\n",
    "        val_loss = []\n",
    "        for _, record in enumerate(pbar := tqdm.tqdm(test_dataset_loader)):\n",
    "            input, label = record\n",
    "            input = input.to(nn_utils.get_device())\n",
    "            label = label.to(nn_utils.get_device())\n",
    "            output = model(input)  # b x n_classes\n",
    "            output = output.to(nn_utils.get_device())\n",
    "\n",
    "            loss = criterion(output, label.long())\n",
    "            curr_val_loss = loss.item()\n",
    "            model.test_iter += 1\n",
    "            if log_loss:\n",
    "                tbw.add_scalar(f\"{model_name}-max_lr{max_lr}/validation-loss\", float(curr_val_loss), model.test_iter)\n",
    "                pbar.set_description(\n",
    "                    f\"{model_name}/validation-loss = {float(curr_val_loss)}, model.n_iter={model.test_iter}, epoch={epoch + 1}\")\n",
    "            val_loss.append(curr_val_loss)\n",
    "            # to get probabilities of the output\n",
    "            output = F.softmax(output, dim=-1)\n",
    "            result_df = pd.DataFrame(output.cpu().numpy())\n",
    "            result_df[\"y_true\"] = label.cpu().numpy()\n",
    "            results.append(result_df)\n",
    "    return pd.concat(results, ignore_index=True), mean(val_loss)\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Main\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    batch_size = 64\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "    model = get_cnn_model({\n",
    "        \"n_classes\": 10,\n",
    "        \"depth\": 2,\n",
    "        \"n_filters\": 3,\n",
    "        \"kernel_size\": 3,\n",
    "        \"stride\": 1,\n",
    "        \"img_size\": 32\n",
    "    })\n",
    "\n",
    "    results_df, _ = run_model(model=model,\n",
    "              train_dataset_loader=train_dataset_loader,\n",
    "              test_dataset_loader=test_dataset_loader,\n",
    "              loss=\"FocalLoss\",\n",
    "              n_epochs=50,\n",
    "              model_name=\"CNN-CIFAR10\",\n",
    "              mode=\"train\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be306532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CNN_2D_Model(\n",
      "  (conv2d): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv2d_hidden): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  (conv2d_hidden_layers): ModuleList(\n",
      "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "  )\n",
      "  (linear): Linear(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters =  30982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 2.005497455596924, model.n_iter=782, epoch=1: 100%|██████████████████████████████████████████████████| 782/782 [00:11<00:00, 68.97it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.799963116645813, model.n_iter=157, epoch=1: 100%|████████████████████████████████████████████████| 157/157 [00:02<00:00, 77.25it/s]\n",
      "CNN-CIFAR10/training-loss = 1.9968056678771973, model.n_iter=1564, epoch=2: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 71.11it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5522332191467285, model.n_iter=314, epoch=2: 100%|███████████████████████████████████████████████| 157/157 [00:01<00:00, 85.55it/s]\n",
      "CNN-CIFAR10/training-loss = 2.1254525184631348, model.n_iter=2346, epoch=3: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 74.53it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.616783618927002, model.n_iter=471, epoch=3: 100%|████████████████████████████████████████████████| 157/157 [00:01<00:00, 86.43it/s]\n",
      "CNN-CIFAR10/training-loss = 1.321088433265686, model.n_iter=3128, epoch=4: 100%|█████████████████████████████████████████████████| 782/782 [00:09<00:00, 80.46it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5224641561508179, model.n_iter=628, epoch=4: 100%|███████████████████████████████████████████████| 157/157 [00:02<00:00, 78.24it/s]\n",
      "CNN-CIFAR10/training-loss = 1.4187264442443848, model.n_iter=3910, epoch=5: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 76.22it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.4665257930755615, model.n_iter=785, epoch=5: 100%|███████████████████████████████████████████████| 157/157 [00:01<00:00, 87.10it/s]\n",
      "CNN-CIFAR10/training-loss = 1.6297763586044312, model.n_iter=4692, epoch=6: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 76.29it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5300977230072021, model.n_iter=942, epoch=6: 100%|███████████████████████████████████████████████| 157/157 [00:01<00:00, 82.30it/s]\n",
      "CNN-CIFAR10/training-loss = 1.4555673599243164, model.n_iter=5474, epoch=7: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 75.07it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.3948616981506348, model.n_iter=1099, epoch=7: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 88.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.6810027360916138, model.n_iter=6256, epoch=8: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 75.31it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.4641616344451904, model.n_iter=1256, epoch=8: 100%|██████████████████████████████████████████████| 157/157 [00:02<00:00, 73.88it/s]\n",
      "CNN-CIFAR10/training-loss = 1.8137720823287964, model.n_iter=7038, epoch=9: 100%|████████████████████████████████████████████████| 782/782 [00:10<00:00, 72.74it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.463633418083191, model.n_iter=1413, epoch=9: 100%|███████████████████████████████████████████████| 157/157 [00:01<00:00, 90.71it/s]\n",
      "CNN-CIFAR10/training-loss = 1.3489887714385986, model.n_iter=7820, epoch=10: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 76.99it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5918210744857788, model.n_iter=1570, epoch=10: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 88.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.1322165727615356, model.n_iter=8602, epoch=11: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 76.74it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.3834476470947266, model.n_iter=1727, epoch=11: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 93.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.6809464693069458, model.n_iter=9384, epoch=12: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 74.53it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5354489088058472, model.n_iter=1884, epoch=12: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 88.95it/s]\n",
      "CNN-CIFAR10/training-loss = 1.193823218345642, model.n_iter=10166, epoch=13: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 74.50it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5135157108306885, model.n_iter=2041, epoch=13: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 79.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.2352699041366577, model.n_iter=10948, epoch=14: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 77.59it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5428766012191772, model.n_iter=2198, epoch=14: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 79.83it/s]\n",
      "CNN-CIFAR10/training-loss = 1.914536476135254, model.n_iter=11730, epoch=15: 100%|███████████████████████████████████████████████| 782/782 [00:09<00:00, 80.19it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.6630088090896606, model.n_iter=2355, epoch=15: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 83.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 0.8784425258636475, model.n_iter=12512, epoch=16: 100%|██████████████████████████████████████████████| 782/782 [00:09<00:00, 80.56it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.6827850341796875, model.n_iter=2512, epoch=16: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 83.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.5634186267852783, model.n_iter=13294, epoch=17: 100%|██████████████████████████████████████████████| 782/782 [00:09<00:00, 81.15it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.580535888671875, model.n_iter=2669, epoch=17: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 90.48it/s]\n",
      "CNN-CIFAR10/training-loss = 1.2597308158874512, model.n_iter=14076, epoch=18: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 76.32it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.506366491317749, model.n_iter=2826, epoch=18: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 87.63it/s]\n",
      "CNN-CIFAR10/training-loss = 1.749234676361084, model.n_iter=14858, epoch=19: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 77.86it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.6993722915649414, model.n_iter=2983, epoch=19: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 88.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 0.949276328086853, model.n_iter=15640, epoch=20: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 77.84it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.580898642539978, model.n_iter=3140, epoch=20: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 89.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.8355581760406494, model.n_iter=16422, epoch=21: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 77.79it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.608489990234375, model.n_iter=3297, epoch=21: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 88.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 3 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.277962565422058, model.n_iter=17204, epoch=22: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 73.06it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.6727125644683838, model.n_iter=3454, epoch=22: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 85.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 4 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.137202501296997, model.n_iter=17986, epoch=23: 100%|███████████████████████████████████████████████| 782/782 [00:10<00:00, 74.52it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.673870325088501, model.n_iter=3611, epoch=23: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 83.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 5 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.2394356727600098, model.n_iter=18768, epoch=24: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 76.82it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.664446473121643, model.n_iter=3768, epoch=24: 100%|██████████████████████████████████████████████| 157/157 [00:01<00:00, 88.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 6 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.0609376430511475, model.n_iter=19550, epoch=25: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 75.80it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.6453896760940552, model.n_iter=3925, epoch=25: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 89.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 7 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.1774474382400513, model.n_iter=20332, epoch=26: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 78.06it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.5704362392425537, model.n_iter=4082, epoch=26: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 90.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 8 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.5566688776016235, model.n_iter=21114, epoch=27: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 77.64it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.7382090091705322, model.n_iter=4239, epoch=27: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 9 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-CIFAR10/training-loss = 1.5171399116516113, model.n_iter=21896, epoch=28: 100%|██████████████████████████████████████████████| 782/782 [00:10<00:00, 77.08it/s]\n",
      "CNN-CIFAR10/validation-loss = 1.7025290727615356, model.n_iter=4396, epoch=28: 100%|█████████████████████████████████████████████| 157/157 [00:01<00:00, 88.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 10 / 10\n",
      "Early STOP: Early stopping threshold reached.\n",
      "Breaking off training loop due to early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 106.73it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe01b37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>0.676966</td>\n",
       "      <td>2.538372e-02</td>\n",
       "      <td>6.445172e-02</td>\n",
       "      <td>0.180722</td>\n",
       "      <td>2.726518e-04</td>\n",
       "      <td>0.026997</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005806</td>\n",
       "      <td>0.683730</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.364514e-07</td>\n",
       "      <td>2.893021e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.526448e-07</td>\n",
       "      <td>0.286974</td>\n",
       "      <td>0.023479</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.635771</td>\n",
       "      <td>0.039265</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>9.364109e-04</td>\n",
       "      <td>1.381257e-02</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>3.633298e-02</td>\n",
       "      <td>0.164494</td>\n",
       "      <td>0.086395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267318</td>\n",
       "      <td>0.042131</td>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.003844</td>\n",
       "      <td>2.723092e-03</td>\n",
       "      <td>1.674157e-03</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>6.129877e-03</td>\n",
       "      <td>0.627427</td>\n",
       "      <td>0.029581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.031662</td>\n",
       "      <td>0.088187</td>\n",
       "      <td>7.064581e-01</td>\n",
       "      <td>6.908988e-02</td>\n",
       "      <td>0.083259</td>\n",
       "      <td>1.988525e-02</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.314838</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.057906</td>\n",
       "      <td>0.219833</td>\n",
       "      <td>3.552399e-02</td>\n",
       "      <td>1.082123e-01</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>1.554670e-02</td>\n",
       "      <td>0.233642</td>\n",
       "      <td>0.012583</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.036595</td>\n",
       "      <td>0.260279</td>\n",
       "      <td>7.905325e-02</td>\n",
       "      <td>1.538853e-01</td>\n",
       "      <td>0.464559</td>\n",
       "      <td>3.076355e-03</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.069840</td>\n",
       "      <td>0.265926</td>\n",
       "      <td>2.403824e-02</td>\n",
       "      <td>5.148486e-01</td>\n",
       "      <td>0.027216</td>\n",
       "      <td>8.355962e-02</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.075319</td>\n",
       "      <td>0.501914</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.072903</td>\n",
       "      <td>1.140959e-01</td>\n",
       "      <td>1.122649e-01</td>\n",
       "      <td>0.062422</td>\n",
       "      <td>2.001339e-02</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.075943</td>\n",
       "      <td>0.052996</td>\n",
       "      <td>8.250807e-02</td>\n",
       "      <td>2.304777e-01</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>5.135778e-01</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.001781</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3             4             5  \\\n",
       "0     0.003510  0.001911  0.019537  0.676966  2.538372e-02  6.445172e-02   \n",
       "1     0.005806  0.683730  0.000002  0.000004  8.364514e-07  2.893021e-07   \n",
       "2     0.635771  0.039265  0.012964  0.009985  9.364109e-04  1.381257e-02   \n",
       "3     0.267318  0.042131  0.018912  0.003844  2.723092e-03  1.674157e-03   \n",
       "4     0.000184  0.000003  0.031662  0.088187  7.064581e-01  6.908988e-02   \n",
       "...        ...       ...       ...       ...           ...           ...   \n",
       "9995  0.314838  0.001216  0.057906  0.219833  3.552399e-02  1.082123e-01   \n",
       "9996  0.001362  0.000007  0.036595  0.260279  7.905325e-02  1.538853e-01   \n",
       "9997  0.000495  0.001814  0.069840  0.265926  2.403824e-02  5.148486e-01   \n",
       "9998  0.075319  0.501914  0.010701  0.072903  1.140959e-01  1.122649e-01   \n",
       "9999  0.005691  0.000422  0.075943  0.052996  8.250807e-02  2.304777e-01   \n",
       "\n",
       "             6             7         8         9  y_true  \n",
       "0     0.180722  2.726518e-04  0.026997  0.000249       3  \n",
       "1     0.000002  8.526448e-07  0.286974  0.023479       8  \n",
       "2     0.000044  3.633298e-02  0.164494  0.086395       8  \n",
       "3     0.000259  6.129877e-03  0.627427  0.029581       0  \n",
       "4     0.083259  1.988525e-02  0.001066  0.000205       6  \n",
       "...        ...           ...       ...       ...     ...  \n",
       "9995  0.000698  1.554670e-02  0.233642  0.012583       8  \n",
       "9996  0.464559  3.076355e-03  0.000775  0.000408       3  \n",
       "9997  0.027216  8.355962e-02  0.001051  0.011212       5  \n",
       "9998  0.062422  2.001339e-02  0.010820  0.019547       1  \n",
       "9999  0.031140  5.135778e-01  0.005464  0.001781       7  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029aa509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC for class 0 = 0.6055322426403852\n",
      "AUPRC for class 1 = 0.6568172694765939\n",
      "AUPRC for class 2 = 0.34150691042283227\n",
      "AUPRC for class 3 = 0.29919740934829064\n",
      "AUPRC for class 4 = 0.3875204563843705\n",
      "AUPRC for class 5 = 0.36611551888814065\n",
      "AUPRC for class 6 = 0.5120589525176913\n",
      "AUPRC for class 7 = 0.56449490195931\n",
      "AUPRC for class 8 = 0.6171756019601253\n",
      "AUPRC for class 9 = 0.5585778921044726\n",
      "Macro AUPRC = 0.4908997155702212\n"
     ]
    }
   ],
   "source": [
    "auprcs = []\n",
    "for i in range(10):\n",
    "    precision, recall, _ = precision_recall_curve(y_true=results_df[\"y_true\"].values, probas_pred=results_df[i].values, pos_label=i)\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC for class {i} = {auprc}\")\n",
    "    auprcs.append(auprc)\n",
    "\n",
    "macro_auprc = mean(auprcs)\n",
    "print(f\"Macro AUPRC = {macro_auprc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11ba2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_2D_MaxPool_Model(nn.Module):\n",
    "    def __init__(self, n_classes, N, n_filters, kernel_size, stride, img_size):\n",
    "        super(CNN_2D_MaxPool_Model, self).__init__()\n",
    "        # padding: same ensures the output has the same size as the input\n",
    "        self.conv2d_1 = Conv2d(in_channels=3,\n",
    "                             out_channels=n_filters,\n",
    "                             kernel_size=kernel_size,\n",
    "                             stride=stride,\n",
    "                             padding=\"same\")\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2d_2 = Conv2d(in_channels=n_filters,\n",
    "                             out_channels=16,\n",
    "                             kernel_size=kernel_size,\n",
    "                             stride=stride,\n",
    "                             padding=\"same\")\n",
    "        \n",
    "        self.linear_1 = nn.Linear(int(16 * img_size/4 * img_size/4), 120)\n",
    "        self.linear_2 = nn.Linear(120, 84)\n",
    "        self.linear_3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.maxpool(F.relu(self.conv2d_1(X)))\n",
    "        X = self.maxpool(F.relu(self.conv2d_2(X)))\n",
    "        X = torch.flatten(X, 1) # flatten all dimensions except batch\n",
    "        \n",
    "        X = F.relu(self.linear_1(X))\n",
    "        X = F.relu(self.linear_2(X))\n",
    "        \n",
    "        y = self.linear_3(X)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_cnn_maxpool_model(model):\n",
    "    cnn_model = CNN_2D_MaxPool_Model(n_classes=model[\"n_classes\"],\n",
    "                             N=model[\"depth\"],\n",
    "                             n_filters=model[\"n_filters\"],\n",
    "                             kernel_size=model[\"kernel_size\"],\n",
    "                             stride=model[\"stride\"],\n",
    "                             img_size=model[\"img_size\"])\n",
    "\n",
    "    print(cnn_model)\n",
    "    print(\"Number of parameters = \", sum(p.numel() for p in cnn_model.parameters() if p.requires_grad))\n",
    "    return cnn_model.to(nn_utils.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e942c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_maxpool():\n",
    "    print(\"Main Max Pool\")\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    batch_size = 64\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataset_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "    model = get_cnn_maxpool_model({\n",
    "        \"n_classes\": 10,\n",
    "        \"depth\": 2,\n",
    "        \"n_filters\": 6,\n",
    "        \"kernel_size\": 5,\n",
    "        \"stride\": 1,\n",
    "        \"img_size\": 32\n",
    "    })\n",
    "\n",
    "    results_df, _ = run_model(model=model,\n",
    "              train_dataset_loader=train_dataset_loader,\n",
    "              test_dataset_loader=test_dataset_loader,\n",
    "              loss=\"FocalLoss\",\n",
    "              n_epochs=50,\n",
    "              model_name=\"CNN-MaxPool-CIFAR10\",\n",
    "              mode=\"train\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0423b7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Max Pool\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "CNN_2D_MaxPool_Model(\n",
      "  (conv2d_1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2d_2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  (linear_1): Linear(in_features=1024, out_features=120, bias=True)\n",
      "  (linear_2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (linear_3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Number of parameters =  136886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 1.5757601261138916, model.n_iter=782, epoch=1: 100%|█████████████████████████████████████████| 782/782 [00:13<00:00, 56.74it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.9495793581008911, model.n_iter=157, epoch=1: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 90.01it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.621734380722046, model.n_iter=1564, epoch=2: 100%|█████████████████████████████████████████| 782/782 [00:10<00:00, 75.40it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.7317614555358887, model.n_iter=314, epoch=2: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 88.08it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.4852652549743652, model.n_iter=2346, epoch=3: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 75.92it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.7497484683990479, model.n_iter=471, epoch=3: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 88.63it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.3120355606079102, model.n_iter=3128, epoch=4: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 74.03it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.49681556224823, model.n_iter=628, epoch=4: 100%|█████████████████████████████████████████| 157/157 [00:01<00:00, 86.97it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.3577719926834106, model.n_iter=3910, epoch=5: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 71.87it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.0361493825912476, model.n_iter=785, epoch=5: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 85.05it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.5044245719909668, model.n_iter=4692, epoch=6: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 71.80it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.2535136938095093, model.n_iter=942, epoch=6: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 86.52it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.3606981039047241, model.n_iter=5474, epoch=7: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 73.70it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.012355923652649, model.n_iter=1099, epoch=7: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 87.29it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.616801381111145, model.n_iter=6256, epoch=8: 100%|█████████████████████████████████████████| 782/782 [00:10<00:00, 71.74it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.455570936203003, model.n_iter=1256, epoch=8: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 83.84it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 0.9742130637168884, model.n_iter=7038, epoch=9: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 73.88it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.136438012123108, model.n_iter=1413, epoch=9: 100%|███████████████████████████████████████| 157/157 [00:01<00:00, 80.67it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 1.322894811630249, model.n_iter=7820, epoch=10: 100%|████████████████████████████████████████| 782/782 [00:10<00:00, 72.49it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.2894988059997559, model.n_iter=1570, epoch=10: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 79.25it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 0.7491583228111267, model.n_iter=8602, epoch=11: 100%|███████████████████████████████████████| 782/782 [00:11<00:00, 70.88it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.4583464860916138, model.n_iter=1727, epoch=11: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 83.66it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 0.7114883065223694, model.n_iter=9384, epoch=12: 100%|███████████████████████████████████████| 782/782 [00:10<00:00, 76.07it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.473419189453125, model.n_iter=1884, epoch=12: 100%|██████████████████████████████████████| 157/157 [00:01<00:00, 86.87it/s]\n",
      "CNN-MaxPool-CIFAR10/training-loss = 0.37237706780433655, model.n_iter=10166, epoch=13: 100%|█████████████████████████████████████| 782/782 [00:11<00:00, 70.75it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.1822232007980347, model.n_iter=2041, epoch=13: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 89.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.7500495314598083, model.n_iter=10948, epoch=14: 100%|██████████████████████████████████████| 782/782 [00:10<00:00, 72.90it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.4235379695892334, model.n_iter=2198, epoch=14: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 82.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.5867986679077148, model.n_iter=11730, epoch=15: 100%|██████████████████████████████████████| 782/782 [00:11<00:00, 68.44it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.7299604415893555, model.n_iter=2355, epoch=15: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 81.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 3 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.6362656950950623, model.n_iter=12512, epoch=16: 100%|██████████████████████████████████████| 782/782 [00:10<00:00, 74.13it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.3182530403137207, model.n_iter=2512, epoch=16: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 88.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 4 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.3416403830051422, model.n_iter=13294, epoch=17: 100%|██████████████████████████████████████| 782/782 [00:11<00:00, 70.08it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.2077089548110962, model.n_iter=2669, epoch=17: 100%|█████████████████████████████████████| 157/157 [00:02<00:00, 75.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 5 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.8885893225669861, model.n_iter=14076, epoch=18: 100%|██████████████████████████████████████| 782/782 [00:10<00:00, 74.74it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.2945828437805176, model.n_iter=2826, epoch=18: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 6 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.6200412511825562, model.n_iter=14858, epoch=19: 100%|██████████████████████████████████████| 782/782 [00:11<00:00, 70.53it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.221171498298645, model.n_iter=2983, epoch=19: 100%|██████████████████████████████████████| 157/157 [00:01<00:00, 92.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 7 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.7601403594017029, model.n_iter=15640, epoch=20: 100%|██████████████████████████████████████| 782/782 [00:10<00:00, 74.15it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.2030200958251953, model.n_iter=3140, epoch=20: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 79.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 8 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.6007446050643921, model.n_iter=16422, epoch=21: 100%|██████████████████████████████████████| 782/782 [00:11<00:00, 70.68it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.1327440738677979, model.n_iter=3297, epoch=21: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 81.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 9 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CNN-MaxPool-CIFAR10/training-loss = 0.6725125312805176, model.n_iter=17204, epoch=22: 100%|██████████████████████████████████████| 782/782 [00:10<00:00, 74.30it/s]\n",
      "CNN-MaxPool-CIFAR10/validation-loss = 1.3234622478485107, model.n_iter=3454, epoch=22: 100%|█████████████████████████████████████| 157/157 [00:01<00:00, 85.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping counter: 10 / 10\n",
      "Early STOP: Early stopping threshold reached.\n",
      "Breaking off training loop due to early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:01<00:00, 104.84it/s]\n"
     ]
    }
   ],
   "source": [
    "results_df_1 = main_maxpool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8219fcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.775296e-05</td>\n",
       "      <td>1.249700e-05</td>\n",
       "      <td>1.818604e-04</td>\n",
       "      <td>9.142494e-01</td>\n",
       "      <td>9.846402e-05</td>\n",
       "      <td>8.513452e-02</td>\n",
       "      <td>8.433924e-06</td>\n",
       "      <td>2.128123e-04</td>\n",
       "      <td>1.921865e-05</td>\n",
       "      <td>5.031317e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.487698e-04</td>\n",
       "      <td>1.363557e-01</td>\n",
       "      <td>2.228991e-08</td>\n",
       "      <td>7.868332e-08</td>\n",
       "      <td>1.264316e-10</td>\n",
       "      <td>2.061656e-08</td>\n",
       "      <td>3.559669e-08</td>\n",
       "      <td>1.117268e-09</td>\n",
       "      <td>8.631737e-01</td>\n",
       "      <td>3.216984e-04</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.977743e-02</td>\n",
       "      <td>3.303924e-04</td>\n",
       "      <td>1.121504e-05</td>\n",
       "      <td>1.117484e-04</td>\n",
       "      <td>5.682932e-06</td>\n",
       "      <td>1.048974e-06</td>\n",
       "      <td>5.097469e-07</td>\n",
       "      <td>9.427195e-06</td>\n",
       "      <td>9.191543e-01</td>\n",
       "      <td>5.981280e-04</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.984623e-01</td>\n",
       "      <td>2.150432e-05</td>\n",
       "      <td>2.710773e-04</td>\n",
       "      <td>2.101128e-05</td>\n",
       "      <td>8.179437e-04</td>\n",
       "      <td>1.337411e-05</td>\n",
       "      <td>9.251529e-08</td>\n",
       "      <td>1.467364e-04</td>\n",
       "      <td>2.275555e-04</td>\n",
       "      <td>1.834625e-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.768320e-09</td>\n",
       "      <td>2.698723e-09</td>\n",
       "      <td>4.125910e-03</td>\n",
       "      <td>1.193616e-01</td>\n",
       "      <td>7.700981e-01</td>\n",
       "      <td>2.446160e-04</td>\n",
       "      <td>1.061489e-01</td>\n",
       "      <td>2.080914e-05</td>\n",
       "      <td>9.225453e-08</td>\n",
       "      <td>3.131278e-09</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2.455725e-02</td>\n",
       "      <td>3.384214e-03</td>\n",
       "      <td>1.898962e-05</td>\n",
       "      <td>1.680849e-01</td>\n",
       "      <td>4.522581e-06</td>\n",
       "      <td>5.822346e-01</td>\n",
       "      <td>4.518705e-06</td>\n",
       "      <td>3.813598e-05</td>\n",
       "      <td>2.216724e-01</td>\n",
       "      <td>4.756793e-07</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2.043237e-07</td>\n",
       "      <td>1.887062e-08</td>\n",
       "      <td>2.869339e-02</td>\n",
       "      <td>6.595091e-01</td>\n",
       "      <td>1.738558e-01</td>\n",
       "      <td>7.539368e-02</td>\n",
       "      <td>5.296532e-02</td>\n",
       "      <td>9.573013e-03</td>\n",
       "      <td>6.913088e-06</td>\n",
       "      <td>2.576378e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2.980013e-05</td>\n",
       "      <td>1.475179e-10</td>\n",
       "      <td>1.809285e-02</td>\n",
       "      <td>2.045206e-01</td>\n",
       "      <td>7.095814e-04</td>\n",
       "      <td>7.716811e-01</td>\n",
       "      <td>1.948756e-04</td>\n",
       "      <td>4.770860e-03</td>\n",
       "      <td>2.195218e-08</td>\n",
       "      <td>2.891947e-07</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3.115217e-02</td>\n",
       "      <td>8.698265e-02</td>\n",
       "      <td>1.639027e-01</td>\n",
       "      <td>5.404172e-02</td>\n",
       "      <td>5.491359e-01</td>\n",
       "      <td>9.774116e-02</td>\n",
       "      <td>8.023535e-03</td>\n",
       "      <td>9.900077e-07</td>\n",
       "      <td>8.946112e-03</td>\n",
       "      <td>7.297987e-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2.324233e-06</td>\n",
       "      <td>4.307960e-07</td>\n",
       "      <td>1.538011e-03</td>\n",
       "      <td>6.042230e-03</td>\n",
       "      <td>6.838552e-01</td>\n",
       "      <td>1.401920e-02</td>\n",
       "      <td>2.986652e-04</td>\n",
       "      <td>2.942420e-01</td>\n",
       "      <td>2.081120e-07</td>\n",
       "      <td>1.772429e-06</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4  \\\n",
       "0     7.775296e-05  1.249700e-05  1.818604e-04  9.142494e-01  9.846402e-05   \n",
       "1     1.487698e-04  1.363557e-01  2.228991e-08  7.868332e-08  1.264316e-10   \n",
       "2     7.977743e-02  3.303924e-04  1.121504e-05  1.117484e-04  5.682932e-06   \n",
       "3     9.984623e-01  2.150432e-05  2.710773e-04  2.101128e-05  8.179437e-04   \n",
       "4     1.768320e-09  2.698723e-09  4.125910e-03  1.193616e-01  7.700981e-01   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  2.455725e-02  3.384214e-03  1.898962e-05  1.680849e-01  4.522581e-06   \n",
       "9996  2.043237e-07  1.887062e-08  2.869339e-02  6.595091e-01  1.738558e-01   \n",
       "9997  2.980013e-05  1.475179e-10  1.809285e-02  2.045206e-01  7.095814e-04   \n",
       "9998  3.115217e-02  8.698265e-02  1.639027e-01  5.404172e-02  5.491359e-01   \n",
       "9999  2.324233e-06  4.307960e-07  1.538011e-03  6.042230e-03  6.838552e-01   \n",
       "\n",
       "                 5             6             7             8             9  \\\n",
       "0     8.513452e-02  8.433924e-06  2.128123e-04  1.921865e-05  5.031317e-06   \n",
       "1     2.061656e-08  3.559669e-08  1.117268e-09  8.631737e-01  3.216984e-04   \n",
       "2     1.048974e-06  5.097469e-07  9.427195e-06  9.191543e-01  5.981280e-04   \n",
       "3     1.337411e-05  9.251529e-08  1.467364e-04  2.275555e-04  1.834625e-05   \n",
       "4     2.446160e-04  1.061489e-01  2.080914e-05  9.225453e-08  3.131278e-09   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "9995  5.822346e-01  4.518705e-06  3.813598e-05  2.216724e-01  4.756793e-07   \n",
       "9996  7.539368e-02  5.296532e-02  9.573013e-03  6.913088e-06  2.576378e-06   \n",
       "9997  7.716811e-01  1.948756e-04  4.770860e-03  2.195218e-08  2.891947e-07   \n",
       "9998  9.774116e-02  8.023535e-03  9.900077e-07  8.946112e-03  7.297987e-05   \n",
       "9999  1.401920e-02  2.986652e-04  2.942420e-01  2.081120e-07  1.772429e-06   \n",
       "\n",
       "      y_true  \n",
       "0          3  \n",
       "1          8  \n",
       "2          8  \n",
       "3          0  \n",
       "4          6  \n",
       "...      ...  \n",
       "9995       8  \n",
       "9996       3  \n",
       "9997       5  \n",
       "9998       1  \n",
       "9999       7  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f105f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC for class 0 = 0.7524650699727221\n",
      "AUPRC for class 1 = 0.8273696235716458\n",
      "AUPRC for class 2 = 0.5753369371556882\n",
      "AUPRC for class 3 = 0.48172726322712794\n",
      "AUPRC for class 4 = 0.6250637314604829\n",
      "AUPRC for class 5 = 0.5901951602144044\n",
      "AUPRC for class 6 = 0.7760028400180341\n",
      "AUPRC for class 7 = 0.7822793126838635\n",
      "AUPRC for class 8 = 0.8425138570007332\n",
      "AUPRC for class 9 = 0.7733447249482502\n",
      "Macro AUPRC = 0.7026298520252953\n"
     ]
    }
   ],
   "source": [
    "auprcs = []\n",
    "for i in range(10):\n",
    "    precision, recall, _ = precision_recall_curve(y_true=results_df_1[\"y_true\"].values, probas_pred=results_df_1[i].values, pos_label=i)\n",
    "    auprc = auc(recall, precision)\n",
    "    print(f\"AUPRC for class {i} = {auprc}\")\n",
    "    auprcs.append(auprc)\n",
    "\n",
    "macro_auprc = mean(auprcs)\n",
    "print(f\"Macro AUPRC = {macro_auprc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb174b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
