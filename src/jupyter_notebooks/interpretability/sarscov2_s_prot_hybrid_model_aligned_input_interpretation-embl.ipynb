{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd64c278",
   "metadata": {},
   "source": [
    "## Interpretation of Hybrid VirProBERT attention values for multiclass classification\n",
    "\n",
    "### Trainining Dataset: UNiRef90  - Coronaviridae Spike protein sequences aligned using MAFFT\n",
    "### Interpretation: SARS-CoV-2 Spike protein sequences\n",
    "\n",
    "**Models**: hybrid_attention_msl256_s64_fnn_2l_d1024_lr1e-4\n",
    "\n",
    "**Positional Embedding**: Sin-Cos\n",
    "\n",
    "**Maximum Sequence Length**: -\n",
    "\n",
    "**Classification**: Multi-class\n",
    "\n",
    "**\\# classes**: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0a7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/interpretability/sarscov2-aligned',\n",
       " '/opt/conda/lib/python38.zip',\n",
       " '/opt/conda/lib/python3.8',\n",
       " '/opt/conda/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/blessyantony/.local/lib/python3.8/site-packages',\n",
       " '/opt/conda/lib/python3.8/site-packages',\n",
       " '/opt/conda/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/blessyantony/.ipython',\n",
       " '/home/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/interpretability/sarscov2-aligned/../../..',\n",
       " '/home/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/interpretability/sarscov2-aligned/../../../..',\n",
       " '/home/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/interpretability/sarscov2-aligned/../..',\n",
       " '/home/blessyantony/dev/git/zoonosis/src/jupyter_notebooks/interpretability/sarscov2-aligned/..']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\", \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "256b5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.nlp.transformer import transformer\n",
    "from models.nlp.hybrid import transformer_attention\n",
    "from datasets.protein_sequence_dataset import ProteinSequenceDataset\n",
    "from src.utils import utils, dataset_utils, nn_utils, constants\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "cmap = sns.color_palette(\"vlag\", as_cmap=True)\n",
    "\n",
    "from sklearn.metrics import roc_curve, accuracy_score, f1_score, auc, precision_recall_curve\n",
    "from statistics import mean\n",
    "\n",
    "# from captum.attr import LayerIntegratedGradients, TokenReferenceBase, LayerGradientXActivation, LayerDeepLift, LayerLRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0c3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_groupings = {\n",
    "                    \"Chicken\": [ \"gallus gallus\" ],\n",
    "                    \"Human\": [ \"homo sapiens\" ],\n",
    "                    \"Cat\": [ \"felis catus\" ],\n",
    "                    \"Pig\": [ \"sus scrofa\" ],\n",
    "                    \"Gray wolf\": [ \"canis lupus\" ],\n",
    "                    \"Horshoe bat\": [\"rhinolophus sp.\"],\n",
    "                    \"Ferret\": [\"mustela putorius\"],\n",
    "                    \"Chinese rufous horseshoe bat\": [\"rhinolophus sinicus\"]\n",
    "                }\n",
    "\n",
    "\n",
    "sequence_settings =  {\n",
    "    \"sequence_col\": \"aligned_seq\",\n",
    "    \"batch_size\": 16,\n",
    "    \"max_sequence_length\": 256,\n",
    "    \"truncate\": False,\n",
    "    \"split_sequence\": False,\n",
    "    \"feature_type\": \"token\"\n",
    "}\n",
    "\n",
    "label_settings = {\n",
    "    \"label_col\": \"virus_host_name\",\n",
    "    \"exclude_labels\": [ \"nan\"],\n",
    "    \"label_groupings\":  label_groupings\n",
    "}\n",
    "\n",
    "model = {\n",
    "    \"pre_train_settings\": {\n",
    "        \"embedding\": \"linear\",\n",
    "        \"n_heads\": 8,\n",
    "        \"depth\": 6,\n",
    "        \"input_dim\": 512, # input embedding dimension\n",
    "        \"hidden_dim\": 1024,\n",
    "        \"max_seq_len\": 256,\n",
    "    },\n",
    "    \"loss\": \"FocalLoss\",\n",
    "    \"n_heads\": 8,\n",
    "    \"depth\": 2,\n",
    "    \"stride\": 64,\n",
    "    \"n_classes\": 8,\n",
    "    \"input_dim\": 512, # input embedding dimension\n",
    "    \"hidden_dim\": 1024\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4b303",
   "metadata": {},
   "source": [
    "### Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc7319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_loader(dataset_loader):\n",
    "    print()\n",
    "    sequence, label = next(iter(dataset_loader))\n",
    "    print(f\"Sequence tensor size = {sequence.shape}\")\n",
    "    print(f\"Sequence = {sequence}\")\n",
    "    print(f\"Label tensor size = {label.shape}\")\n",
    "    print(f\"Label = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e657b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniref90_id</th>\n",
       "      <th>aligned_seq</th>\n",
       "      <th>seq</th>\n",
       "      <th>virus_name</th>\n",
       "      <th>virus_host_name</th>\n",
       "      <th>human_binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIV04</td>\n",
       "      <td>--------------MFVFLVLLPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>WIV04(MN996528.1) Wuhan variant index virus</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef90_A0A7U3RIT3</td>\n",
       "      <td>--------------MFVFLVLVPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef90_A0A7U3HGG2</td>\n",
       "      <td>--------------MFVFLVLLPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef90_A0A7U3EEN6</td>\n",
       "      <td>--------------MFVFLVLLPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef90_A0A7U3HDM5</td>\n",
       "      <td>--------------MFVFLVLLPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus 2</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>UniRef90_S5FZ76</td>\n",
       "      <td>---------------------------TLKQ---------------...</td>\n",
       "      <td>TLKQCDASAGYYSSSPIRPSDGVHSVTGFYRPVKTCCIKYTYPSNT...</td>\n",
       "      <td>Infectious bronchitis virus</td>\n",
       "      <td>gallus gallus</td>\n",
       "      <td>NOT homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>UniRef90_U5WLM9</td>\n",
       "      <td>--------------MLLLVTLFGLASG-------------------...</td>\n",
       "      <td>MLLLVTLFGLASGCSLPLTVSCPRGLPFTLQINTTSVTVEWYRVSP...</td>\n",
       "      <td>Sarbecovirus</td>\n",
       "      <td>rhinolophus sinicus</td>\n",
       "      <td>NOT homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>UniRef90_A0A169QA14</td>\n",
       "      <td>--MILHF-IMKVMPILIMVVFILL----------------------...</td>\n",
       "      <td>MILHFIMKVMPILIMVVFILLVYTNTHSSEWLLLFYFLISGVFCLY...</td>\n",
       "      <td>Infectious bronchitis virus</td>\n",
       "      <td>gallus gallus</td>\n",
       "      <td>NOT homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>UniRef90_E7DBM7</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>CSRRQFENYNQIEKVHVH</td>\n",
       "      <td>Feline coronavirus</td>\n",
       "      <td>felis catus</td>\n",
       "      <td>NOT homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>UniRef90_U3U789</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>LIVKDVSLTLFKNHDGKLYLTPRTTYEPRVAT</td>\n",
       "      <td>Ferret coronavirus</td>\n",
       "      <td>mustela putorius</td>\n",
       "      <td>NOT homo sapiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             uniref90_id                                        aligned_seq  \\\n",
       "0                  WIV04  --------------MFVFLVLLPLVSS--------Q----------...   \n",
       "1    UniRef90_A0A7U3RIT3  --------------MFVFLVLVPLVSS--------Q----------...   \n",
       "2    UniRef90_A0A7U3HGG2  --------------MFVFLVLLPLVSS--------Q----------...   \n",
       "3    UniRef90_A0A7U3EEN6  --------------MFVFLVLLPLVSS--------Q----------...   \n",
       "4    UniRef90_A0A7U3HDM5  --------------MFVFLVLLPLVSS--------Q----------...   \n",
       "..                   ...                                                ...   \n",
       "677      UniRef90_S5FZ76  ---------------------------TLKQ---------------...   \n",
       "678      UniRef90_U5WLM9  --------------MLLLVTLFGLASG-------------------...   \n",
       "679  UniRef90_A0A169QA14  --MILHF-IMKVMPILIMVVFILL----------------------...   \n",
       "680      UniRef90_E7DBM7  ----------------------------------------------...   \n",
       "681      UniRef90_U3U789  ----------------------------------------------...   \n",
       "\n",
       "                                                   seq  \\\n",
       "0    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "1    MFVFLVLVPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "2    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "3    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "4    MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "..                                                 ...   \n",
       "677  TLKQCDASAGYYSSSPIRPSDGVHSVTGFYRPVKTCCIKYTYPSNT...   \n",
       "678  MLLLVTLFGLASGCSLPLTVSCPRGLPFTLQINTTSVTVEWYRVSP...   \n",
       "679  MILHFIMKVMPILIMVVFILLVYTNTHSSEWLLLFYFLISGVFCLY...   \n",
       "680                                 CSRRQFENYNQIEKVHVH   \n",
       "681                   LIVKDVSLTLFKNHDGKLYLTPRTTYEPRVAT   \n",
       "\n",
       "                                          virus_name      virus_host_name  \\\n",
       "0        WIV04(MN996528.1) Wuhan variant index virus         homo sapiens   \n",
       "1    Severe acute respiratory syndrome coronavirus 2         homo sapiens   \n",
       "2    Severe acute respiratory syndrome coronavirus 2         homo sapiens   \n",
       "3    Severe acute respiratory syndrome coronavirus 2         homo sapiens   \n",
       "4    Severe acute respiratory syndrome coronavirus 2         homo sapiens   \n",
       "..                                               ...                  ...   \n",
       "677                      Infectious bronchitis virus        gallus gallus   \n",
       "678                                     Sarbecovirus  rhinolophus sinicus   \n",
       "679                      Infectious bronchitis virus        gallus gallus   \n",
       "680                               Feline coronavirus          felis catus   \n",
       "681                               Ferret coronavirus     mustela putorius   \n",
       "\n",
       "    human_binary_label  \n",
       "0         homo sapiens  \n",
       "1         homo sapiens  \n",
       "2         homo sapiens  \n",
       "3         homo sapiens  \n",
       "4         homo sapiens  \n",
       "..                 ...  \n",
       "677   NOT homo sapiens  \n",
       "678   NOT homo sapiens  \n",
       "679   NOT homo sapiens  \n",
       "680   NOT homo sapiens  \n",
       "681   NOT homo sapiens  \n",
       "\n",
       "[682 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file_path = os.path.join(os.getcwd(), \"..\", \"..\", \"..\", \"..\", \"input/data/coronaviridae/20240313/uniref/alignment/coronaviridae_s_uniref90_embl_hosts_pruned_metadata_corrected_species_virus_host_vertebrates_w_seq_t0.01_c8_aligned.csv\")\n",
    "uniref90_coronaviridae_aligned_df = pd.read_csv(input_file_path)\n",
    "wiv04_seq_df = uniref90_coronaviridae_aligned_df[uniref90_coronaviridae_aligned_df[\"uniref90_id\"] == \"WIV04\"]\n",
    "uniref90_coronaviridae_aligned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15c88a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping labels using config : {'Chicken': ['gallus gallus'], 'Human': ['homo sapiens'], 'Cat': ['felis catus'], 'Pig': ['sus scrofa'], 'Gray wolf': ['canis lupus'], 'Horshoe bat': ['rhinolophus sp.'], 'Ferret': ['mustela putorius'], 'Chinese rufous horseshoe bat': ['rhinolophus sinicus']}\n",
      "label_idx_map={'Cat': 0, 'Chicken': 1, 'Chinese rufous horseshoe bat': 2, 'Ferret': 3, 'Gray wolf': 4, 'Horshoe bat': 5, 'Human': 6, 'Pig': 7}\n",
      "idx_label_map={0: 'Cat', 1: 'Chicken', 2: 'Chinese rufous horseshoe bat', 3: 'Ferret', 4: 'Gray wolf', 5: 'Horshoe bat', 6: 'Human', 7: 'Pig'}\n",
      "\n",
      "Sequence tensor size = torch.Size([16, 2418])\n",
      "Sequence = tensor([[27., 27., 27.,  ...,  0.,  0.,  0.],\n",
      "        [27., 27., 27.,  ..., 27., 27., 27.],\n",
      "        [27., 27., 27.,  ..., 27., 27., 27.],\n",
      "        ...,\n",
      "        [27., 27., 27.,  ..., 27., 27., 27.],\n",
      "        [27., 27., 27.,  ..., 27., 27., 27.],\n",
      "        [27., 27., 27.,  ..., 27., 27., 27.]], dtype=torch.float64)\n",
      "Label tensor size = torch.Size([16])\n",
      "Label = tensor([1, 1, 0, 1, 1, 1, 1, 6, 1, 3, 7, 2, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "index_label_map, dataset_loader = dataset_utils.load_dataset_with_df(uniref90_coronaviridae_aligned_df, sequence_settings, label_settings, label_col=label_settings[\"label_col\"], classification_type=\"multi\")\n",
    "print_dataset_loader(dataset_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab719dd1",
   "metadata": {},
   "source": [
    "### Load the pre-trained and fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18bd3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerEncoder(\n",
      "  (embedding): EmbeddingLayer(\n",
      "    (token_embedding): Embedding(28, 512, padding_idx=0)\n",
      "    (positional_embedding): PositionalEncoding()\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForwardLayer(\n",
      "          (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "          (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "        )\n",
      "        (residual_connections): ModuleList(\n",
      "          (0): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "          (1): ResidualConnectionLayer(\n",
      "            (norm): NormalizationLayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): NormalizationLayer()\n",
      "  )\n",
      ")\n",
      "Number of parameters =  12618752\n"
     ]
    }
   ],
   "source": [
    "pre_train_encoder_settings = model[\"pre_train_settings\"]\n",
    "pre_train_encoder_settings[\"vocab_size\"] = constants.VOCAB_SIZE\n",
    "pre_trained_encoder_model = transformer.get_transformer_encoder(pre_train_encoder_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0031a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VirProBERT(\n",
      "  (pre_trained_model): TransformerEncoder(\n",
      "    (embedding): EmbeddingLayer(\n",
      "      (token_embedding): Embedding(28, 512, padding_idx=0)\n",
      "      (positional_embedding): PositionalEncoding()\n",
      "    )\n",
      "    (encoder): Encoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (4): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (5): EncoderLayer(\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (feed_forward): FeedForwardLayer(\n",
      "            (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "            (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "          )\n",
      "          (residual_connections): ModuleList(\n",
      "            (0): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "            (1): ResidualConnectionLayer(\n",
      "              (norm): NormalizationLayer()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): NormalizationLayer()\n",
      "    )\n",
      "  )\n",
      "  (self_attn): MultiHeadAttention(\n",
      "    (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (W_O): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (feed_forward): FeedForwardLayer(\n",
      "    (W_1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (W_2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  )\n",
      "  (linear_ip): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (linear_hidden): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (linear_hidden_n): ModuleList(\n",
      "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  )\n",
      "  (linear_op): Linear(in_features=1024, out_features=8, bias=True)\n",
      ")\n",
      "Number of parameters =  18401800\n"
     ]
    }
   ],
   "source": [
    "model[\"pre_trained_model\"] = pre_trained_encoder_model\n",
    "model[\"chunk_len\"] = pre_train_encoder_settings[\"max_seq_len\"]\n",
    "prediction_model = transformer_attention.get_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe14fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(os.getcwd(), \"..\", \"..\", \"..\", \"..\", \"output/raw/coronaviridae_s_prot_uniref90_embl_vertebrates_aligned_t0.01_c8/20240701/host_multi/fine_tuning_hybrid/mlm_tfenc_l6_h8_lr1e-4_uniref90viridae_msl256_hybrid_attention_s64_fnn_2l_d1024_lr1e-4_itr0.pth\")\n",
    "prediction_model.load_state_dict(torch.load(model_path, map_location=nn_utils.get_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e77de3",
   "metadata": {},
   "source": [
    "### t-SNE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f6a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(model, dataset_loader):\n",
    "    model.eval()\n",
    "    seq_dfs = []\n",
    "    for _, record in enumerate(dataset_loader):\n",
    "        seq, label = record\n",
    "        output = model(seq)\n",
    "        # embedding = value for each dimension = mean of the dimensional values of all tokens in the input sequence\n",
    "        seq_encoding = model.embedding\n",
    "        seq_df = pd.DataFrame(seq_encoding.squeeze().cpu().detach().numpy())\n",
    "        seq_df[\"label\"] = label.squeeze().cpu().detach().numpy()\n",
    "        seq_dfs.append(seq_df)\n",
    "    df = pd.concat(seq_dfs)\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "def view_tsne_representation(rep_df, index_label_map):\n",
    "    columns = rep_df.columns\n",
    "    print(columns)\n",
    "    X = rep_df[range(512)]\n",
    "    tsne_model = TSNE(n_components=2, verbose=1, init=\"pca\", learning_rate=\"auto\").fit(X)\n",
    "    X_tsne_emb = pd.DataFrame(tsne_model.fit_transform(X))\n",
    "    print(X_tsne_emb.shape)\n",
    "    print(X_tsne_emb)\n",
    "    X_tsne_emb[\"label\"] = rep_df[\"label\"].values\n",
    "    X_tsne_emb[\"label\"] = X_tsne_emb[\"label\"].map(index_label_map)\n",
    "    \n",
    "    sns.scatterplot(data = X_tsne_emb, x=0, y=1, hue=\"label\")\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "    plt.show()\n",
    "    return tsne_model, X_tsne_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cba83ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_df = compute_embeddings(prediction_model, dataset_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e854b6",
   "metadata": {},
   "source": [
    "### Attention value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2032bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_attention_of_sequence(model, seq):\n",
    "    print(f\"sequence length = {seq_len}\")\n",
    "    model.eval()\n",
    "    output = model(seq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406b856c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniref90_id</th>\n",
       "      <th>aligned_seq</th>\n",
       "      <th>seq</th>\n",
       "      <th>virus_name</th>\n",
       "      <th>virus_host_name</th>\n",
       "      <th>human_binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WIV04</td>\n",
       "      <td>--------------MFVFLVLLPLVSS--------Q----------...</td>\n",
       "      <td>MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...</td>\n",
       "      <td>WIV04(MN996528.1) Wuhan variant index virus</td>\n",
       "      <td>homo sapiens</td>\n",
       "      <td>homo sapiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniref90_id                                        aligned_seq  \\\n",
       "0       WIV04  --------------MFVFLVLLPLVSS--------Q----------...   \n",
       "\n",
       "                                                 seq  \\\n",
       "0  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...   \n",
       "\n",
       "                                    virus_name virus_host_name  \\\n",
       "0  WIV04(MN996528.1) Wuhan variant index virus    homo sapiens   \n",
       "\n",
       "  human_binary_label  \n",
       "0       homo sapiens  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiv04_seq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c58128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiv04_seq_df[\"aligned_seq\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5489d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping labels using config : {'Chicken': ['gallus gallus'], 'Human': ['homo sapiens'], 'Cat': ['felis catus'], 'Pig': ['sus scrofa'], 'Gray wolf': ['canis lupus'], 'Horshoe bat': ['rhinolophus sp.'], 'Ferret': ['mustela putorius'], 'Chinese rufous horseshoe bat': ['rhinolophus sinicus']}\n",
      "label_idx_map={'Cat': 0, 'Chicken': 1, 'Chinese rufous horseshoe bat': 2, 'Ferret': 3, 'Gray wolf': 4, 'Horshoe bat': 5, 'Human': 6, 'Pig': 7}\n",
      "idx_label_map={0: 'Cat', 1: 'Chicken', 2: 'Chinese rufous horseshoe bat', 3: 'Ferret', 4: 'Gray wolf', 5: 'Horshoe bat', 6: 'Human', 7: 'Pig'}\n"
     ]
    }
   ],
   "source": [
    "sequence_settings[\"batch_size\"] = 1\n",
    "sequence_settings[\"max_sequence_length\"] = 256\n",
    "\n",
    "_, wiv04_seq_df_dataset_loader = dataset_utils.load_dataset_with_df(wiv04_seq_df, sequence_settings, label_settings, label_col=label_settings[\"label_col\"], classification_type=\"multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d2d2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_model.eval()\n",
    "#output = prediction_model(next(iter(wiv04_seq_df_dataset_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d4d734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq, label = next(iter(wiv04_seq_df_dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d30bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1a06c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
       "         13., 14., 22., 14., 11., 22., 11., 11., 15., 11., 22., 17., 17., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27.,  6., 27., 27., 27., 27., 27., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,  5., 22.,  3., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27., 11., 19., 19.,  2., 19.,  6., 11.,\n",
       "         15., 15.,  1., 21., 27., 27., 27., 27., 19.,  3., 17., 14., 19.,  2.,\n",
       "          8., 22., 21., 21., 15.,  4., 12., 22., 14.,  2., 17., 17., 22., 11.,\n",
       "          9., 17., 19.,  6.,  4., 11., 14., 11., 15., 14., 27., 27., 27., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 14., 17.,\n",
       "          3., 22., 19., 20., 14.,  9.,  1., 10.,  9., 22., 17.,  8., 19., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
       "          3.,  8., 19., 12.,  2., 14.,  4.,  3., 15., 22., 11., 15., 14.,  3.,\n",
       "         27.,  4.,  8., 22., 21., 14.,  1., 17., 19.,  7., 12., 27., 27., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 17.,  3., 10., 10.,  2.,  8., 20., 10.,\n",
       "         14.,  8., 19., 19., 11.,  4., 17., 12., 19.,  6., 17., 11., 11., 10.,\n",
       "         22.,  3.,  3.,  1., 19., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
       "         27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
       "         27., 27., 27., 27.,  3., 27., 27., 27., 27., 27., 27., 27., 27., 27.,\n",
       "         27., 27., 27., 27.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42e9fc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence_col': 'aligned_seq',\n",
       " 'batch_size': 1,\n",
       " 'max_sequence_length': 256,\n",
       " 'truncate': False,\n",
       " 'split_sequence': False,\n",
       " 'feature_type': 'token'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1238c1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiv04_seq_df_dataset_loader.dataset.data[wiv04_seq_df_dataset_loader.dataset.sequence_col][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b482d68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2418])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiv04_seq_df_dataset_loader.dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4cba38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2418])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "098f440f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2418])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(wiv04_seq_df_dataset_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee0221db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = wiv04_seq_df_dataset_loader.dataset.__getitem__(0)\n",
    "# sequences = [seq.clone().detach() for seq in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d5d5835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27., 27., 27.,  ..., 19., 27., 27.], dtype=torch.float64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f98ee897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ConstantPad1d((0, 256 - sequences.shape[0]), 0)(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0f34c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2418])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "pad_sequence([sequences], batch_first=True, padding_value=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef34d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
